[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RELOD ebook",
    "section": "",
    "text": "Preface\nRE-LOD - Testing the Limits Of remote sensing for Detecting forest and woodland structural and biomass REcovery\nProject team: Beth Raine, Lindsay Banin, Richard Broughton, Charles George, and Michael Tso (UKCEH)\nThis e-book provides additional markdown documents that contain code snippets to showcase some of the analysis discussed in the RE-LOD project report.\nAll of the content of this repository is licensed CC0.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "sh_RS_comparison.html#comparing-estimated-height-from-point-cloud-with-heights-measured-on-the-ground",
    "href": "sh_RS_comparison.html#comparing-estimated-height-from-point-cloud-with-heights-measured-on-the-ground",
    "title": "3  Strawberry Hill analysis",
    "section": "3.1 Comparing estimated height from point cloud with heights measured on the ground:",
    "text": "3.1 Comparing estimated height from point cloud with heights measured on the ground:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Strawberry Hill analysis</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html",
    "href": "lidar_processing.html",
    "title": "3  LiDAR data processing",
    "section": "",
    "text": "3.1 Pre-processing steps\nThis R script takes a pre-processed point cloud from a UAV drone pass file .laz or .las. It reads the files in using the LAStools package, which is a separate executable programme which can be implemented through R. .laz files are zipped versions of .las files. They can be good for storing large amounts of data, however they do take time to unzip each time you use them so are not always better than .las files for storing drone data.\nA really useful place to start is the lidR package which has detailed tutorials: lidR book: https://r-lidar.github.io/lidRbook/index.html This lays out a lot of the preprocessing steps:\nreadLAS(filter = “-help”)\ncan thin the dataset before you read it filter = “xyz” removes all but the point cloud data filter = “-keep_first” : commonly used in forestry filter = “-keep_every_nth x” used for thinning out the point cloud to reduce the size",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html#pre-processing-steps",
    "href": "lidar_processing.html#pre-processing-steps",
    "title": "3  LiDAR data processing",
    "section": "",
    "text": "3.1.1 Thinning and filtering:\n\n# Load a LAScatalog instead of a LAS file\n## try reading the full las file and thin it:\n\n# this is a big file and it does take a while to load even when thinned\n# try thin_with_grid\nlas_first &lt;- readLAS(here(\"data-raw\", \"lidar\", \"Knepp_points_processed_merged.las\"),\n             filter = \"-keep_first\")\nwriteLAS(las_first, here(\"data-raw\", \"lidar\", \"knepp_full_keep_first.las\"))\n# make sure you have the most up to date version of lidR\n\n# this is one every 20cm - this is still very high resolution and probably enough for processing\nlas_100th &lt;- lidR::readLAS(here(\"data-raw\", \"lidar\" \"Knepp_points_processed_merged.las\"), \n                    filter = \"-keep_every_nth 100\")\n\nwriteLAS(las_100th, here(\"data-output\", \"lidar_outputs\", \"knepp_full_thin_100.las\"))\n\nlas_10th &lt;- readLAS(here(\"data-raw\", \"lidar\", \"Knepp_points_processed_merged.las\"),\n               filter = \"-keep_every_nth 10\")\nwriteLAS(las_10th, here(\"data-raw\", \"lidar\", \"knepp_full_thin_10.las\"))\n\n\n\n3.1.2 Retiling:\nSplitting into smaller tiles for ease of processing\n\nctg &lt;- readLAScatalog(here(\"data-output\", \"lidar_outputs\", \"knepp_full_thin_100.las\"))\nopt_chunk_buffer(ctg) &lt;- 0\nopt_chunk_size(ctg) &lt;- 250\nopt_output_files(ctg) &lt;- paste0(\"data-output/lidar_outputs/las_cat_10\", \"/retile_{XLEFT}_{YBOTTOM}\")\nplot(ctg, chunk = TRUE)\ncatalog_retile(ctg)\n\nLoading in our .las file:\n\n# Process it like a LAS file\nctg &lt;- readLAScatalog(here(\"data-output/lidar_outputs/las_cat_100\"))\n\nlas &lt;- readLAS(ctg,filter = \"-drop_z_below 0\")\n\n#plot(las)\n\n\n\n3.1.3 Classifying the ground\nI think this had already been done in the original knepp point cloud. So this is redoing that as it isn’t always accurate. It includes pmf, csf and mcc for ground classification. ws = Sequence of windows sizes to be used in filtering ground returns. The values must be positive and in the same units as the point cloud (usually meters, occasionally feet).\nth = numeric. Sequence of threshold heights above the parameterized ground surface to be considered a ground return. The values must be positive and in the same units as the point cloud. Values used here as in “Estimating Forest Structure from UAV-Mounted LiDAR Point Cloud Using Machine Learning”\n\n# this is time consuming\n#ws &lt;- seq(0.5, 2.5, 3)\n#th &lt;- seq(0.1,0.5, length.out = length(ws))\n\n# this function extracts some default ws and th values to use from \n# the Zhang paper\n\np &lt;- util_makeZhangParam(\n  b = 2,\n  dh0 = 0.5,\n  dhmax = 3,\n  s = 1,\n  max_ws = 20,\n  exp = FALSE\n)\nlas &lt;- classify_ground(las, algorithm = pmf(ws = p$ws, th = p$th))\n\nMorphological filter: 4% (1 threads)\nMorphological filter: 5% (1 threads)\nMorphological filter: 6% (1 threads)\nMorphological filter: 7% (1 threads)\nMorphological filter: 8% (1 threads)\nMorphological filter: 9% (1 threads)\nMorphological filter: 10% (1 threads)\nMorphological filter: 11% (1 threads)\nMorphological filter: 12% (1 threads)\nMorphological filter: 13% (1 threads)\nMorphological filter: 14% (1 threads)\nMorphological filter: 15% (1 threads)\nMorphological filter: 16% (1 threads)\nMorphological filter: 17% (1 threads)\nMorphological filter: 18% (1 threads)\nMorphological filter: 19% (1 threads)\nMorphological filter: 20% (1 threads)\nMorphological filter: 21% (1 threads)\nMorphological filter: 22% (1 threads)\nMorphological filter: 23% (1 threads)\nMorphological filter: 24% (1 threads)\nMorphological filter: 25% (1 threads)\nMorphological filter: 26% (1 threads)\nMorphological filter: 27% (1 threads)\nMorphological filter: 28% (1 threads)\nMorphological filter: 29% (1 threads)\nMorphological filter: 30% (1 threads)\nMorphological filter: 31% (1 threads)\nMorphological filter: 32% (1 threads)\nMorphological filter: 33% (1 threads)\nMorphological filter: 34% (1 threads)\nMorphological filter: 35% (1 threads)\nMorphological filter: 36% (1 threads)\nMorphological filter: 37% (1 threads)\nMorphological filter: 38% (1 threads)\nMorphological filter: 39% (1 threads)\nMorphological filter: 40% (1 threads)\nMorphological filter: 41% (1 threads)\nMorphological filter: 42% (1 threads)\nMorphological filter: 43% (1 threads)\nMorphological filter: 44% (1 threads)\nMorphological filter: 45% (1 threads)\nMorphological filter: 46% (1 threads)\nMorphological filter: 47% (1 threads)\nMorphological filter: 48% (1 threads)\nMorphological filter: 49% (1 threads)\nMorphological filter: 50% (1 threads)\nMorphological filter: 51% (1 threads)\nMorphological filter: 52% (1 threads)\nMorphological filter: 53% (1 threads)\nMorphological filter: 54% (1 threads)\nMorphological filter: 55% (1 threads)\nMorphological filter: 56% (1 threads)\nMorphological filter: 57% (1 threads)\nMorphological filter: 58% (1 threads)\nMorphological filter: 59% (1 threads)\nMorphological filter: 60% (1 threads)\nMorphological filter: 61% (1 threads)\nMorphological filter: 62% (1 threads)\nMorphological filter: 63% (1 threads)\nMorphological filter: 64% (1 threads)\nMorphological filter: 65% (1 threads)\nMorphological filter: 66% (1 threads)\nMorphological filter: 67% (1 threads)\nMorphological filter: 68% (1 threads)\nMorphological filter: 69% (1 threads)\nMorphological filter: 70% (1 threads)\nMorphological filter: 71% (1 threads)\nMorphological filter: 72% (1 threads)\nMorphological filter: 73% (1 threads)\nMorphological filter: 74% (1 threads)\nMorphological filter: 75% (1 threads)\nMorphological filter: 76% (1 threads)\nMorphological filter: 77% (1 threads)\nMorphological filter: 78% (1 threads)\nMorphological filter: 79% (1 threads)\nMorphological filter: 80% (1 threads)\nMorphological filter: 81% (1 threads)\nMorphological filter: 82% (1 threads)\nMorphological filter: 83% (1 threads)\nMorphological filter: 84% (1 threads)\nMorphological filter: 85% (1 threads)\nMorphological filter: 86% (1 threads)\nMorphological filter: 87% (1 threads)\nMorphological filter: 88% (1 threads)\nMorphological filter: 89% (1 threads)\nMorphological filter: 90% (1 threads)\nMorphological filter: 91% (1 threads)\nMorphological filter: 92% (1 threads)\nMorphological filter: 93% (1 threads)\nMorphological filter: 94% (1 threads)\nMorphological filter: 95% (1 threads)\nMorphological filter: 96% (1 threads)\nMorphological filter: 97% (1 threads)\nMorphological filter: 98% (1 threads)\nMorphological filter: 99% (1 threads)\nMorphological filter: 3% (1 threads)\nMorphological filter: 4% (1 threads)\nMorphological filter: 5% (1 threads)\nMorphological filter: 6% (1 threads)\nMorphological filter: 7% (1 threads)\nMorphological filter: 8% (1 threads)\nMorphological filter: 9% (1 threads)\nMorphological filter: 10% (1 threads)\nMorphological filter: 11% (1 threads)\nMorphological filter: 12% (1 threads)\nMorphological filter: 13% (1 threads)\nMorphological filter: 14% (1 threads)\nMorphological filter: 15% (1 threads)\nMorphological filter: 16% (1 threads)\nMorphological filter: 17% (1 threads)\nMorphological filter: 18% (1 threads)\nMorphological filter: 19% (1 threads)\nMorphological filter: 20% (1 threads)\nMorphological filter: 21% (1 threads)\nMorphological filter: 22% (1 threads)\nMorphological filter: 23% (1 threads)\nMorphological filter: 24% (1 threads)\nMorphological filter: 25% (1 threads)\nMorphological filter: 26% (1 threads)\nMorphological filter: 27% (1 threads)\nMorphological filter: 28% (1 threads)\nMorphological filter: 29% (1 threads)\nMorphological filter: 30% (1 threads)\nMorphological filter: 31% (1 threads)\nMorphological filter: 32% (1 threads)\nMorphological filter: 33% (1 threads)\nMorphological filter: 34% (1 threads)\nMorphological filter: 35% (1 threads)\nMorphological filter: 36% (1 threads)\nMorphological filter: 37% (1 threads)\nMorphological filter: 38% (1 threads)\nMorphological filter: 39% (1 threads)\nMorphological filter: 40% (1 threads)\nMorphological filter: 41% (1 threads)\nMorphological filter: 42% (1 threads)\nMorphological filter: 43% (1 threads)\nMorphological filter: 44% (1 threads)\nMorphological filter: 45% (1 threads)\nMorphological filter: 46% (1 threads)\nMorphological filter: 47% (1 threads)\nMorphological filter: 48% (1 threads)\nMorphological filter: 49% (1 threads)\nMorphological filter: 50% (1 threads)\nMorphological filter: 51% (1 threads)\nMorphological filter: 52% (1 threads)\nMorphological filter: 53% (1 threads)\nMorphological filter: 54% (1 threads)\nMorphological filter: 55% (1 threads)\nMorphological filter: 56% (1 threads)\nMorphological filter: 57% (1 threads)\nMorphological filter: 58% (1 threads)\nMorphological filter: 59% (1 threads)\nMorphological filter: 60% (1 threads)\nMorphological filter: 61% (1 threads)\nMorphological filter: 62% (1 threads)\nMorphological filter: 63% (1 threads)\nMorphological filter: 64% (1 threads)\nMorphological filter: 65% (1 threads)\nMorphological filter: 66% (1 threads)\nMorphological filter: 67% (1 threads)\nMorphological filter: 68% (1 threads)\nMorphological filter: 69% (1 threads)\nMorphological filter: 70% (1 threads)\nMorphological filter: 71% (1 threads)\nMorphological filter: 72% (1 threads)\nMorphological filter: 73% (1 threads)\nMorphological filter: 74% (1 threads)\nMorphological filter: 75% (1 threads)\nMorphological filter: 76% (1 threads)\nMorphological filter: 77% (1 threads)\nMorphological filter: 78% (1 threads)\nMorphological filter: 79% (1 threads)\nMorphological filter: 80% (1 threads)\nMorphological filter: 81% (1 threads)\nMorphological filter: 82% (1 threads)\nMorphological filter: 83% (1 threads)\nMorphological filter: 84% (1 threads)\nMorphological filter: 85% (1 threads)\nMorphological filter: 86% (1 threads)\nMorphological filter: 87% (1 threads)\nMorphological filter: 88% (1 threads)\nMorphological filter: 89% (1 threads)\nMorphological filter: 90% (1 threads)\nMorphological filter: 91% (1 threads)\nMorphological filter: 92% (1 threads)\nMorphological filter: 93% (1 threads)\nMorphological filter: 94% (1 threads)\nMorphological filter: 95% (1 threads)\nMorphological filter: 96% (1 threads)\nMorphological filter: 97% (1 threads)\nMorphological filter: 98% (1 threads)\nMorphological filter: 99% (1 threads)\nMorphological filter: 2% (1 threads)\nMorphological filter: 3% (1 threads)\nMorphological filter: 4% (1 threads)\nMorphological filter: 5% (1 threads)\nMorphological filter: 6% (1 threads)\nMorphological filter: 7% (1 threads)\nMorphological filter: 8% (1 threads)\nMorphological filter: 9% (1 threads)\nMorphological filter: 10% (1 threads)\nMorphological filter: 11% (1 threads)\nMorphological filter: 12% (1 threads)\nMorphological filter: 13% (1 threads)\nMorphological filter: 14% (1 threads)\nMorphological filter: 15% (1 threads)\nMorphological filter: 16% (1 threads)\nMorphological filter: 17% (1 threads)\nMorphological filter: 18% (1 threads)\nMorphological filter: 19% (1 threads)\nMorphological filter: 20% (1 threads)\nMorphological filter: 21% (1 threads)\nMorphological filter: 22% (1 threads)\nMorphological filter: 23% (1 threads)\nMorphological filter: 24% (1 threads)\nMorphological filter: 25% (1 threads)\nMorphological filter: 26% (1 threads)\nMorphological filter: 27% (1 threads)\nMorphological filter: 28% (1 threads)\nMorphological filter: 29% (1 threads)\nMorphological filter: 30% (1 threads)\nMorphological filter: 31% (1 threads)\nMorphological filter: 32% (1 threads)\nMorphological filter: 33% (1 threads)\nMorphological filter: 34% (1 threads)\nMorphological filter: 35% (1 threads)\nMorphological filter: 36% (1 threads)\nMorphological filter: 37% (1 threads)\nMorphological filter: 38% (1 threads)\nMorphological filter: 39% (1 threads)\nMorphological filter: 40% (1 threads)\nMorphological filter: 41% (1 threads)\nMorphological filter: 42% (1 threads)\nMorphological filter: 43% (1 threads)\nMorphological filter: 44% (1 threads)\nMorphological filter: 45% (1 threads)\nMorphological filter: 46% (1 threads)\nMorphological filter: 47% (1 threads)\nMorphological filter: 48% (1 threads)\nMorphological filter: 49% (1 threads)\nMorphological filter: 50% (1 threads)\nMorphological filter: 51% (1 threads)\nMorphological filter: 52% (1 threads)\nMorphological filter: 53% (1 threads)\nMorphological filter: 54% (1 threads)\nMorphological filter: 55% (1 threads)\nMorphological filter: 56% (1 threads)\nMorphological filter: 57% (1 threads)\nMorphological filter: 58% (1 threads)\nMorphological filter: 59% (1 threads)\nMorphological filter: 60% (1 threads)\nMorphological filter: 61% (1 threads)\nMorphological filter: 62% (1 threads)\nMorphological filter: 63% (1 threads)\nMorphological filter: 64% (1 threads)\nMorphological filter: 65% (1 threads)\nMorphological filter: 66% (1 threads)\nMorphological filter: 67% (1 threads)\nMorphological filter: 68% (1 threads)\nMorphological filter: 69% (1 threads)\nMorphological filter: 70% (1 threads)\nMorphological filter: 71% (1 threads)\nMorphological filter: 72% (1 threads)\nMorphological filter: 73% (1 threads)\nMorphological filter: 74% (1 threads)\nMorphological filter: 75% (1 threads)\nMorphological filter: 76% (1 threads)\nMorphological filter: 77% (1 threads)\nMorphological filter: 78% (1 threads)\nMorphological filter: 79% (1 threads)\nMorphological filter: 80% (1 threads)\nMorphological filter: 81% (1 threads)\nMorphological filter: 82% (1 threads)\nMorphological filter: 83% (1 threads)\nMorphological filter: 84% (1 threads)\nMorphological filter: 85% (1 threads)\nMorphological filter: 86% (1 threads)\nMorphological filter: 87% (1 threads)\nMorphological filter: 88% (1 threads)\nMorphological filter: 89% (1 threads)\nMorphological filter: 90% (1 threads)\nMorphological filter: 91% (1 threads)\nMorphological filter: 92% (1 threads)\nMorphological filter: 93% (1 threads)\nMorphological filter: 94% (1 threads)\nMorphological filter: 95% (1 threads)\nMorphological filter: 96% (1 threads)\nMorphological filter: 97% (1 threads)\nMorphological filter: 98% (1 threads)\nMorphological filter: 99% (1 threads)\nMorphological filter: 1% (1 threads)\nMorphological filter: 2% (1 threads)\nMorphological filter: 3% (1 threads)\nMorphological filter: 4% (1 threads)\nMorphological filter: 5% (1 threads)\nMorphological filter: 6% (1 threads)\nMorphological filter: 7% (1 threads)\nMorphological filter: 8% (1 threads)\nMorphological filter: 9% (1 threads)\nMorphological filter: 10% (1 threads)\nMorphological filter: 11% (1 threads)\nMorphological filter: 12% (1 threads)\nMorphological filter: 13% (1 threads)\nMorphological filter: 14% (1 threads)\nMorphological filter: 15% (1 threads)\nMorphological filter: 16% (1 threads)\nMorphological filter: 17% (1 threads)\nMorphological filter: 18% (1 threads)\nMorphological filter: 19% (1 threads)\nMorphological filter: 20% (1 threads)\nMorphological filter: 21% (1 threads)\nMorphological filter: 22% (1 threads)\nMorphological filter: 23% (1 threads)\nMorphological filter: 24% (1 threads)\nMorphological filter: 25% (1 threads)\nMorphological filter: 26% (1 threads)\nMorphological filter: 27% (1 threads)\nMorphological filter: 28% (1 threads)\nMorphological filter: 29% (1 threads)\nMorphological filter: 30% (1 threads)\nMorphological filter: 31% (1 threads)\nMorphological filter: 32% (1 threads)\nMorphological filter: 33% (1 threads)\nMorphological filter: 34% (1 threads)\nMorphological filter: 35% (1 threads)\nMorphological filter: 36% (1 threads)\nMorphological filter: 37% (1 threads)\nMorphological filter: 38% (1 threads)\nMorphological filter: 39% (1 threads)\nMorphological filter: 40% (1 threads)\nMorphological filter: 41% (1 threads)\nMorphological filter: 42% (1 threads)\nMorphological filter: 43% (1 threads)\nMorphological filter: 44% (1 threads)\nMorphological filter: 45% (1 threads)\nMorphological filter: 46% (1 threads)\nMorphological filter: 47% (1 threads)\nMorphological filter: 48% (1 threads)\nMorphological filter: 49% (1 threads)\nMorphological filter: 50% (1 threads)\nMorphological filter: 51% (1 threads)\nMorphological filter: 52% (1 threads)\nMorphological filter: 53% (1 threads)\nMorphological filter: 54% (1 threads)\nMorphological filter: 55% (1 threads)\nMorphological filter: 56% (1 threads)\nMorphological filter: 57% (1 threads)\nMorphological filter: 58% (1 threads)\nMorphological filter: 59% (1 threads)\nMorphological filter: 60% (1 threads)\nMorphological filter: 61% (1 threads)\nMorphological filter: 62% (1 threads)\nMorphological filter: 63% (1 threads)\nMorphological filter: 64% (1 threads)\nMorphological filter: 65% (1 threads)\nMorphological filter: 66% (1 threads)\nMorphological filter: 67% (1 threads)\nMorphological filter: 68% (1 threads)\nMorphological filter: 69% (1 threads)\nMorphological filter: 70% (1 threads)\nMorphological filter: 71% (1 threads)\nMorphological filter: 72% (1 threads)\nMorphological filter: 73% (1 threads)\nMorphological filter: 74% (1 threads)\nMorphological filter: 75% (1 threads)\nMorphological filter: 76% (1 threads)\nMorphological filter: 77% (1 threads)\nMorphological filter: 78% (1 threads)\nMorphological filter: 79% (1 threads)\nMorphological filter: 80% (1 threads)\nMorphological filter: 81% (1 threads)\nMorphological filter: 82% (1 threads)\nMorphological filter: 83% (1 threads)\nMorphological filter: 84% (1 threads)\nMorphological filter: 85% (1 threads)\nMorphological filter: 86% (1 threads)\nMorphological filter: 87% (1 threads)\nMorphological filter: 88% (1 threads)\nMorphological filter: 89% (1 threads)\nMorphological filter: 90% (1 threads)\nMorphological filter: 91% (1 threads)\nMorphological filter: 92% (1 threads)\nMorphological filter: 93% (1 threads)\nMorphological filter: 94% (1 threads)\nMorphological filter: 95% (1 threads)\nMorphological filter: 96% (1 threads)\nMorphological filter: 97% (1 threads)\nMorphological filter: 98% (1 threads)\nMorphological filter: 99% (1 threads)\n\n#las &lt;- classify_ground(las, algorithm = pmf())\n\n# this is 3d so wont render on datalabs\n#plot(las, color = \"Classification\", size = 3, bg = \"white\") \n\n\n# can subset out the ground just to look at that:\n\ngnd &lt;- filter_ground(las)\n# this plots the point cloud of the ground\n\n\nplot(gnd, size = 3, bng= \"white\")\n\n\n### cloth fold simulation method of ground classification: \n\nlibrary(RCSF)\n\nmycsf &lt;- csf(sloop_smooth = FALSE, rigidness = 2)\nlas &lt;- classify_ground(las, mycsf)\n\n#plot_crossection(las, colour_by = factor(Classification))\n\n# plotting cross sections of the ground\n#las_f &lt;- las\n#las_f@data$Classification &lt;- as.factor(las_f@data$Classification)\n#levels(las_f@data$Classification) &lt;- c(\"ground\", \"low veg\", \"med veg\", \"high veg\",\n#                                     \"building\", \"noise\", \"10\",\"13\", \"14\" ,\n#                                     \"15\", \"18\", \"22\" )\n\nv_n &lt;- seq(0.1, 0.95, by = 0.1)\nfor(i in 1:length(v_n)){\n  n &lt;- v_n[i]\n  p1 = c(min(las@data$X), quantile(las@data$Y, n))\n  p2 = c(max(las@data$X), quantile(las@data$Y,n))\n  data_clip &lt;- clip_transect(las, p1, p2, 4)\n  \n  g &lt;- ggplot(data_clip@data, aes(X,Z, colour= factor(Classification))) + \n    geom_point(size = 0.5) + \n    #coord_equal() + \n    theme(axis.title.y=element_blank(),\n          axis.title.x=element_blank()) +\n    theme(legend.position=\"bottom\") +\n    scale_colour_brewer(palette= \"Paired\")\n  \n  assign(paste0(\"g_\", n), g)\n  \n}\n\n\nggarrange(g_0.1, g_0.2, g_0.3, g_0.4, g_0.5,\n          g_0.6, g_0.7, g_0.8, g_0.9,\n          ncol = 1, \n          common.legend = T, \n          legend.position = \"bottom\")\n\n# can also use the cloth simulation to select the ground\n# or multiscale curvature classification",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html#the-digital-terrain-model",
    "href": "lidar_processing.html#the-digital-terrain-model",
    "title": "3  LiDAR data processing",
    "section": "3.2 The digital terrain model:",
    "text": "3.2 The digital terrain model:\nDTM is the image of the ground do this after you have classified the ground\nhave different methods like invert distance weighting, kriging triangular irregular network\n\ndtm_tin &lt;- rasterize_terrain(las, res = 2, algorithm = tin())\nplot(dtm_tin)\nif(FALSE){\nplot_dtm3d(dtm_tin, bg = \"white\") \n}\n\n# duifferent ways of producing digital terrain model\n#dtm &lt;- rasterize_terrain(las, algorithm = tin(), pkg =\"terra\")\nif(FALSE){\nplot_dtm3d(dtm, bg = \"white\") \n}\n\n\n#dtm_prod &lt;- terrain(dtm, v = c(\"slope\", \"aspect\"), unit = \"radians\")\n#dtm_hillshade &lt;- shade(slope = dtm_prod$slope, aspect = dtm_prod$aspect)\nif(FALSE){\nplot(dtm_hillshade, col =gray(0:30/30), legend = FALSE)\n}\nif(FALSE){\ndtm &lt;- raster::raster(dtm_tin)\n\nelmat &lt;- raster_to_matrix(dtm)\nmap &lt;- elmat %&gt;%\n  sphere_shade(texture = \"imhof1\", progbar = FALSE) %&gt;%\n  add_water(detect_water(elmat), color = \"imhof1\") %&gt;%\n  add_shadow(ray_shade(elmat, progbar = FALSE), 0.5) %&gt;%\n  add_shadow(ambient_shade(elmat, progbar = FALSE), 0)\n\nplot_map(map)\n\n### can then normalise the height based on the dtm:\nnlas &lt;- normalize_height(las, knnidw())\n\nplot(nlas, size = 4, bg = \"white\")\n\n# here I've just manually removed Z values &lt; 0 which is not good:\n  # its a sign that the dtm has incorrectly classified the ground\n  # at several points: but there were only like 3 isolated points so \n  # for now I think this is fine.\n  \n  nlas &lt;- nlas[nlas@data$Z &gt;0,]\n  plot(nlas, size = 4, bg = \"white\")\n  \n  hist(filter_ground(nlas)$Z,   breaks = seq(-0.6, 0.6, 0.01), main = \"\", xlab = \"Elevation\")\n  }",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html#classification-term",
    "href": "lidar_processing.html#classification-term",
    "title": "3  LiDAR data processing",
    "section": "3.3 Classification term",
    "text": "3.3 Classification term\nclassification listed as numbers 2,3,4,5,6,10,13,15,18,22 table(las@data$Classification)\nchrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/http://www.asprs.org/wp-content/uploads/2019/07/LAS_1_4_r15.pdf\nASPRS specification of standard point classes: 0 = Created, never classified 1 = unclassified 2 = ground 3 = low vegetation 4 = medium vegetation 5 = high vegetation 6 = building 7 = low point (noise) 8 = model key point (mass point) 9 = water 10, 11 = reserved for ASPRS definition 12 = overlap points 13 - 31 = reserved for ASPRS definition\nCan change classification based on rules:\n\n# Classifies the points that are NOT in the lake and that are NOT ground points as class 5\n\n################\n#plot(las, color = \"Classification\")\n\nnonveg &lt;- filter_poi(las, Classification != LASHIGHVEGETATION)\nveg &lt;- filter_poi(las, Classification == LASHIGHVEGETATION)\n\nplot(las, color = \"Classification\", bg = \"white\", size = 3)\n\n## cross section 2d rendering:\nsummary(las)\n\n## function:\n\nplot_crossection &lt;- function(las,\n                             p1 = c(min(las@data$X), mean(las@data$Y)),\n                             p2 = c(max(las@data$X), mean(las@data$Y)),\n                             width = 4, colour_by = NULL)\n{\n  colour_by &lt;- enquo(colour_by)\n  data_clip &lt;- clip_transect(las, p1, p2, width)\n  p &lt;- ggplot(data_clip@data, aes(X,Z)) + \n    geom_point(size = 0.5) + \n    coord_equal() + \n    theme_minimal()\n  \n  if (!is.null(colour_by))\n    p &lt;- p + aes(color = !!colour_by) + labs(color = \"\") +\n    theme(legend.position=\"bottom\")\n  \n  return(p)\n}\n\nplot_crossection(las)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html#digital-surface-model-and-canopy-height-model",
    "href": "lidar_processing.html#digital-surface-model-and-canopy-height-model",
    "title": "3  LiDAR data processing",
    "section": "3.4 DIGITAL SURFACE MODEL and canopy height model:",
    "text": "3.4 DIGITAL SURFACE MODEL and canopy height model:\nraster layer that report the highest elevation for the ALS returns\n\n# Can specify the thr and the edg\n# Can specify point to raster based or triangulation based\n# Includes the Khosravirpour et al pitfree algorithm\n\nchm &lt;- rasterize_canopy(las, res = 2, algorithm = p2r())\ncol &lt;- height.colors(25)\nplot(chm, col = col)\n\n# can decrease the resolution to cover the empty areas\n# can add a circle of known radius that simulates that the laser is not a point\n# but a circle\n\n# can also fill in the unfilled areas by kriging\n# this is more time consuming\n# but it also looks a LOT BETTER\nchm &lt;- rasterize_canopy(las, res = 0.5, p2r(0.2, na.fill = tin()))\nplot(chm, col = col)\n\n#png(\"outputs/chm_11_01.png\", width = 15, height = 15, units = \"cm\", res = 600)\n#plot(chm, col= col)\n#dev.off()\n\n#plot(chm, color = \"Intensity\", bg = \"white\", legend = TRUE)\n\n# overlays: need a dtm for this to work\n# think this is a pop out\nx &lt;- plot(las, bg = \"white\", size = 3)\nadd_dtm3d(x, chm)\n\n\n# lidR does not include tools to fill empty pixels but terra does:\nif(FALSE){\n  fill.na &lt;- function(x, i=5) { \n    if (is.na(x)[i]) { return(mean(x, na.rm = TRUE)) } else { return(x[i]) }}\n  \n  w &lt;- matrix(1, 3, 3)\n  \n  chm &lt;- rasterize_canopy(las, res = 0.5, \n                          algorithm = p2r(subcircle = 0.25), pkg = \"terra\")\n  filled &lt;- terra::focal(chm, w, fun = fill.na)\n  smoothed &lt;- terra::focal(chm, w, fun = mean, na.rm = TRUE)\n  \n  chms &lt;- c(chm, filled, smoothed)\n  names(chms) &lt;- c(\"Base\", \"Filled\", \"Smoothed\")\n  plot(chms, col = col)\n}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html#locating-trees",
    "href": "lidar_processing.html#locating-trees",
    "title": "3  LiDAR data processing",
    "section": "3.5 Locating trees:",
    "text": "3.5 Locating trees:\n\n# lmf(ws, hmin = 2, shape = c(\"circular\", \"square\"), ws_args = \"Z\")\n# ws:    numeric or function. Length or diameter of the moving window \n# used to detect the local maxima in the units of the input data \n# (usually meters). If it is numeric a fixed window size is used. \n# If it is a function, the function determines the size of the window \n# at any given location on the canopy. By default function takes the \n# height of a given pixel or point as its only argument and return the\n# desired size of the search window when centered on that pixel/point. \n# This can be controled with the 'ws_args' parameter.\n\n# hmin: numeric. Minimum height of a tree. Threshold below which a \n# pixel or a point cannot be a local maxima. Default is 2.\n\n# shape: character. Shape of the moving window used to find the local \n# maxima. Can be \"square\" or \"circular\".\n\n# ws_args: list. Named list of argument for the function 'ws' if 'ws'\n# is a function.\n\nttops &lt;- locate_trees(las, lmf(ws = 20)) \nplot(chm, col = height.colors(50))\nplot(sf::st_geometry(ttops), add = TRUE, pch = 3)\n\n#png(\"outputs/ttops_11_01_ws20.png\", width = 15, height = 15, units = \"cm\", res #= 600)\n\n#plot(chm, col = height.colors(50))\n#plot(sf::st_geometry(ttops), add = TRUE, pch = 3)\n\n#dev.off()\n\n# plot the point cloud\n# It's somehow added on a tree that's 60m tall in the middle of the plot\n# that has no data to support it\n\noffsets &lt;- plot(las, bg = \"white\", size = 3)\nadd_treetops3d(offsets, ttops)\n# num,ber of trees detected is related to the ws value:\n\nttops_3m &lt;- locate_trees(las, lmf(ws = 3))\nttops_11m &lt;- locate_trees(las, lmf(ws = 11))\n\npar(mfrow=c(1,2))\nplot(chm, col = height.colors(50))\nplot(sf::st_geometry(ttops_3m), add = TRUE, pch = 3)\nplot(chm, col = height.colors(50))\nplot(sf::st_geometry(ttops_11m), add = TRUE, pch = 3)\n\n# extract the coordinates of the trees and apply the shift to display the lines\n# in the rendering coordinate system\n\nx &lt;- sf::st_coordinates(ttops)[,1] - offsets[1] \ny &lt;- sf::st_coordinates(ttops)[,2] - offsets[2] \nz &lt;- ttops$Z\n\n\n# Build a GL_LINES matrix for fast rendering\nx &lt;- rep(x, each = 2)\ny &lt;- rep(y, each = 2)\ntmp &lt;- numeric(2*length(z)) \ntmp[2*1:length(z)] &lt;- z\nz &lt;- tmp\nM &lt;- cbind(x,y,z)\n\n# Display lines\nrgl::segments3d(M, col = \"black\", lwd = 2)\n\n\n# individual segmentation:\n\nalgo &lt;- dalponte2016(chm, ttops)\nt &lt;- segment_trees(las, algo) # segment point cloud\nplot(t, bg = \"white\", size = 4, color = \"treeID\") # visualize trees\n# dont feel that confident about this1\n\n# extrtact crowns:\n\ncrowns &lt;- crown_metrics(t, func = .stdtreemetrics, geom = \"convex\")\nplot(crowns[\"convhull_area\"], main = \"Crown area (convex hull)\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html",
    "href": "gedi_exploration.html",
    "title": "2  GEDI data exploration",
    "section": "",
    "text": "2.1 GEDI data products:\nMore detail on the data type can be found on the GEDI website (https://gedi.umd.edu/data/products/), but a brief summary is as follows:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#gedi-data-products",
    "href": "gedi_exploration.html#gedi-data-products",
    "title": "2  GEDI data exploration",
    "section": "",
    "text": "Level 1A data is not available for download as it is the completely raw waveform.\nLevel 1B data is the location of each of the waveforms\nLevel 2B data includes canopy cover fraction, canopy cover profile, leaf area index and leaf area index profile\nLevel 3 data (not explored here) gives gridded metrics of the level 2 data at a 1x1km resolution globally.\nLevel 4A gives footprint level aboveground biomass. See Dubayah (2022 - doi:10.1088/1748-9326/ac8694)\nLevel 4B gives a gridded metric of the level 4A data, at a 1x1km resolution globally.\n\n\n2.1.1 Interpreting GEDI data:\nThe GEDI lidar fires shots from 8 beams on the satellite at regular spaced intervals. By the time the shots reach earth, they have a 25m radius. The reflectance from the shots are collected by the satellite. This gives us a 3D imprint of the 25m footprint that the shot has reached. As such, we don’t get detail about the exact positioning of objects on the ground, but rather we get a profile of heights. From this it is possible to calculate additional metrics such as the ground level, canopy height, complexity etc.\n\n\n2.1.2 What is the difference between the beams?\nhttps://forum.earthdata.nasa.gov/viewtopic.php?t=756\nCoverage beams: 0000, 0001, 0010, 0011\nFull power beam: 0101, 0110, 1000, 1011\nGEDI coverage beams (beams 0000, 0001, 0010, and 0011) were designed to penetrate canopies of up to 95% canopy cover under “average” conditions. For this reason, it is recommended to preference the GEDI full power beams in cases of dense vegetation.\nStudies have shown that full power beams are more accurate at estimating canopy height in tropical forests (Lahssini (2022), and should be used, together with quality control for high sensitivity (&gt;0.98) shots only.\n\n\n2.1.3 Processing GEDI data\nThe H5 structure of the GEDI data mean that they are not always simple to access and navigate through. The rGEDI package was developed to process Level 1 and 2 data (https://github.com/carlos-alberto-silva/rGEDI). This package can be useful for an introduction to how to navigate through the files and what you can access from them. However, this package is not flexible: it fails to open and navigate through the h5 files if you have a GEDI beam that had one or more lasers turned off during the flight. The figures it produces are not valid if you have any shots missing.\n\n\n2.1.4 This script:\nThis script opens GEDI beam data from April 2019 to May 2022 and goes through manipulating and using this data. It then compares the GEDI footprint data to the drone collected small footprint lidar pass from Knepp estate in 2021.\n\n\n2.1.5 ISSUES:\n\n2b plots assume beams are sequential with 60m distances between them: this is not the case as they are sampled from different time periods so this distance should be derived from the coordinates rather than a standard 60m\nMissing beams affects use of rGEDI download, opening h5 files and as a result the use of all other functions in rGEDI - Why are some beams missing? I think because at various times some beams are turned off for maintenance\nNeed to check: currently from the 1b data all we have is the location and shot number, want ideally to be able to carry out the quality control on the data at this level and then only pull through the ones we want in 2a/2b etc.\nQuality flagging of data for the 2b plots\nTODO: make sure all quality control is carried out in the data processing file before we get here, so the files are all clean and ready to use\n\n\n# packages\n# rGEDI requires hdf5r package, which requires the HDF5 Linux library. Run `sudo apt update` and then `sudo apt-get install libhdf5-dev` in the terminal for Linux or Mac\n\n#library(devtools)\n#devtools::install_git(\"https://github.com/carlos-alberto-silva/rGEDI\", dependencies = TRUE)\n#devtools::install_github(\"VangiElia/GEDI4R\")\n \n\nlibrary(rGEDI) # for processing gedi data\nlibrary(GEDI4R)\n# need to do like an , if not here install this package\nlibrary(terra) # for processing rasters\nlibrary(leaflet) # for producing plots with the ESRI baselayers\nlibrary(leafsync)# \nlibrary(rasterVis) #\nlibrary(viridis) # colour palettes\nlibrary(htmltools)\nlibrary(here) # relative filepaths\nlibrary(tidyverse) # data wrangling\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(ggpubr) # grouping ggplots\nlibrary(mapview) # plotting maps\nlibrary(knitr)\nlibrary(mapview) # follow this to work on DataLabs (PhantomJS): https://gist.github.com/julionc/7476620\nlibrary(webshot)\n\ntheme_set(theme_classic())\n\n# creating a world map for plotting\nworld &lt;- ne_countries(scale=\"medium\", returnclass=\"sf\")\nworld &lt;- sf::st_as_sf(world, coords=c(\"x\",\"y\"), crs = 27700, agr = \"constant\", remove = F)\n\n# outline of Knepp:\n\n#-0.376, -0.362, 50.97, 50.98\n#-0.3764441, -0.363777, 50.97191, 50.98188 \n#v &lt;- vect(\"POLYGON ((-0.376 50.97 , -0.376 50.98, -0.362 50.98,  -0.362 50.97))\")\n\n#v_mask &lt;- vect(here(\"data-raw\", \"knepp_rwild.shp\"))\n#v &lt;- vect(here(\"datasets/KneppWildVeg\", \"rewildedfields.shp\"))\n#v &lt;- terra::project(v, \"EPSG:4326\")\n\nv_mask &lt;- vect(here(\"data-raw\", \"knepp_mask\", \"knepp_mask.shp\"))\nv_mask &lt;- terra::project(v_mask, \"epsg:4326\")#  \"+proj=longlat +datum=WGS84\"\n\n# shape files of the shots:\nsp_1b &lt;- terra::vect(here(\"data-output/gedi/\", \"g1b_full.shp\"))\nsp_2a &lt;- terra::vect(here(\"data-output/gedi/\", \"g2a_full.shp\"))\nsp_2b &lt;- terra::vect(here(\"data-output/gedi/\", \"g2b_full.shp\"))\n\n# dataframes of the shot data:\n# be sure to read in the shot number as a character at this point otherwise it will default to numeric and cut off the end of the value\n\ndf_1b_wave &lt;- read.csv(here(\"data-output/gedi/\", \"g1b_wave_dat.csv\"),\n                       row.names = 1, colClasses=c(\"shot_number\" = \"character\"))\ndf_1b_shot &lt;- read.csv(here(\"data-output/gedi/\", \"g1b_shot_dat.csv\"), \n                       row.names = 1, colClasses=c(\"shot_number\" = \"character\"))\n\ndf_1b_shot$date &lt;- as.Date(df_1b_shot$date)\ndf_1b_shot &lt;- df_1b_shot[df_1b_shot$date &gt; as.Date(\"2021-05-01\"),]\ndf_1b_shot &lt;- df_1b_shot[df_1b_shot$date &lt; as.Date(\"2022-05-01\"),]\n\ndf_1b_wave &lt;- df_1b_wave[df_1b_wave$shot_number %in% df_1b_shot$shot_number,]\n\n#df_2a &lt;- read.csv(here(\"data-output/gedi/\", \"g2a_full.csv\"), \n#                  row.names = 1, colClasses = c(\"shot_number\" = \"character\"))\n#df_2b &lt;- as.data.frame(vect(here(\"data-output/gedi/\", \"g2b_QC.shp\")))\n                       \n### turn them into osgb from lat long: easier to interpret as metres\ncrs(sp_2a) &lt;- \"epsg:4326\"\nsp_2a &lt;- terra::mask(sp_2a, v_mask)\nsp_2a &lt;- terra::project(sp_2a, \"EPSG:27700\")\n\ncrs(sp_2b) &lt;- \"epsg:4326\"\nsp_2b &lt;- terra::mask(sp_2b, v_mask)\nsp_2b &lt;- terra::project(sp_2b, \"EPSG:27700\")\n\ndf_2a &lt;- as.data.frame(sp_2a, geom= \"XY\")\ndf_2b &lt;- as.data.frame(sp_2b, geom = \"XY\")\n\nnames(df_2a)[1:9] &lt;- c(\"beam\", \"shot_number\", \"degrade_flag\",\"quality_flag\",\n                       \"delta_time\", \"sensitivity\", \"solar_elevation\", \"elev_highestmode\",\n                       \"elev_lowestmode\")\nnames(df_2b) &lt;- c(\"beam\", \"shot_number\", \"algorithm\", \"l2b_quality\",\"delta_time\", \n                  \"elev_highestmode\", \"elev_lowestmode\", \"height_last\", \"height_bin\",\n                  \"cover\", \"pai\", \"omega\", \"fhd_normal\", \n                  paste0(\"pai_z\", seq(0,145, by = 5), \"_\",seq(0,145, by = 5)+5),\n                  paste0(\"pavd_z\", seq(0,145, by = 5), \"_\",seq(0,145, by = 5)+5),\n                  \"x\", \"y\")\n\n\n# creating a dataframe as a lookup table for the different beams\nbeam &lt;- c(\"BEAM0000\", \"BEAM0001\", \"BEAM0010\", \"BEAM0011\",\n          \"BEAM0101\", \"BEAM0110\", \"BEAM1000\", \"BEAM1011\")\n\nv_coverage &lt;- c(rep(\"coverage\", 4), rep(\"full\", 4))\ndf_beams &lt;- as.data.frame(cbind(beam, v_coverage))\n\n#shp_4a &lt;- terra::vect(\"GEDI/g4A_all.shp\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#level-1b",
    "href": "gedi_exploration.html#level-1b",
    "title": "2  GEDI data exploration",
    "section": "2.2 Level 1B",
    "text": "2.2 Level 1B\nProcessing information in python: https://lpdaac.usgs.gov/resources/e-learning/getting-started-gedi-l1b-version-2-data-python/\nUser manual: https://lpdaac.usgs.gov/documents/987/GEDI01B_User_Guide_V2.pdf\nData dictionary: https://lpdaac.usgs.gov/documents/981/gedi_l1b_dictionary_P003_v2.html\nThe level 1B data gives us the waveform information from each shot. This data format is useful if you want to derive your own metrics from the waveform, or extract specific information from the vertical height profile.\nI think that because this is the rawest form data you can download, it doesn’t have the same quality control metrics that you find in the level 2 products. The idea being that if you wanted to, you could design your own quality flag from the data rather than interpreting it from this.\n\n# plotting an individual waveform:\ndf_shot1 &lt;- df_1b_wave[df_1b_wave$shot_number == df_1b_wave$shot_number[1],]\n\nggplot(df_shot1, aes(x= elevation, y = rxwaveform)) +\n  geom_line(colour= \"red\") +\n  theme(legend.position = \"none\") +\n  ggtitle(\"Single shot waveform\")\n\n\n\n\n\n\n\ndim(df_shot1)\n\n[1] 737   6\n\n# we get 759 returns from one single shot showing the relative elevation",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#level-2a",
    "href": "gedi_exploration.html#level-2a",
    "title": "2  GEDI data exploration",
    "section": "2.3 Level 2A",
    "text": "2.3 Level 2A\nProcessing: https://lpdaac.usgs.gov/resources/e-learning/getting-started-gedi-l2a-version-2-data-python/\nDetails: https://lpdaac.usgs.gov/products/gedi02_bv002/\nUser guide: https://lpdaac.usgs.gov/documents/998/GEDI02_UserGuide_V21.pdf\nThis is the level 1B waveform grouped into bins of relative height at a 1% interval.\nHere we can use the relative height bins, together with the ground elevation (elev_lowestmode) to construct a canopy height model and a digital elevation model.\n\n2.3.1 Interpreting RH values:\nQuestion: why are there negative values in the rh?? https://lpdaac.usgs.gov/documents/986/GEDI02_UserGuide_V2.pdf\n“Relative Height is calculated by the following equation: elev_highestreturn - elev_lowestmode. The lower RH metrics (e.g., RH10) will often have negative values, particularly in low canopy cover conditions. This is because a relatively high fraction of the waveform energy is from the ground and below elev_lowestmode. For example, if the ground return contains 30% of the energy, then RH1 through 15 are likely to be below 0 since half of the ground energy from the ground return is below the center of the ground return, which is used to determine the mean ground elevation in the footprint (elev_lowestmode). The RH metrics are intended for vegetated surfaces. Results over bare/water surfaces are still valid but may present some confusing results. See Section 6 of the Level 2 User Guide for more detailed information.”\n\n# Quality control:\n# want quality flag to be 1\n# degrade flag &lt; 1\n# sensitivity over 0.95\n# best to use data collected at night (solar_elevation &lt;0)\n# also want to use data that has a quality flag of 1\n\ndf_2a &lt;- df_2a[df_2a$quality_flag ==1,]\ndf_2a &lt;- df_2a[df_2a$degrade_flag &lt; 1,]\ndf_2a &lt;- df_2a[df_2a$sensitivity &gt; 0.9, ] #sufficient for over land\ndf_2a &lt;- df_2a[df_2a$shot_number %in% df_1b_shot$shot_number,]\n#df_2a &lt;- df_2a[df_2a$sensitivity &gt; 0.95, ] #better for some conditions e.g. dense forest\n\na &lt;- ggplot(df_2a, aes(x= x, y = rh100)) +\n  geom_point(alpha= 0.2)  +\n  geom_line(alpha = 0.2) +\n  theme(legend.position = \"none\") +\n  ylab(\"Relative elevation (m)\") +\n  xlab(\"Distance along transect (m)\") +\n  scale_x_continuous(labels=c(0, 200, 400, 600, 800)) +\n  ggtitle(\"Canopy height model\")\n\nb &lt;- ggplot(df_2a, aes(x= x, y = elev_lowestmode)) +\n  geom_point(alpha= 0.2)  +\n  geom_line(alpha = 0.2) +\n  theme(legend.position = \"none\") +\n  ylab(\"Relative elevation (m)\") +\n  xlab(\"Distance along transect (m)\") +\n  scale_x_continuous(labels=c(0, 200, 400, 600, 800)) +\n  ggtitle(\"Digital elevation model\")\n\nggarrange(a,b, ncol=2)\n\n\n\n\n\n\n\n# this is the digital elevation model\ndf_2al &lt;- df_2a %&gt;% gather(class, rel_height, grep(\"rh\", names(df_2a)))\ndf_2al$absolute_height &lt;- df_2al$elev_lowestmode + df_2al$rel_height\ndf_2al &lt;- df_2al[df_2al$rel_height &gt;0,]\ndf_2a$max_height &lt;- df_2a$rh100 + df_2a$elev_lowestmode\ndf_2al &lt;- left_join(df_2al, df_2a[,c(\"shot_number\", \"max_height\")], by= \"shot_number\")\n\na &lt;- ggplot(df_2al, aes(x= x, y = rel_height)) +\n  geom_point(alpha= 0.2, size = 1, col= \"darkgreen\") +\n  ylab(\"Relative elevation (m)\") +\n  xlab(\"Distance along transect (m)\") +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(labels=c(0, 200, 400, 600, 800))\n\nb &lt;- ggplot() +\n  geom_point(data = df_2al, aes(x= x, y = absolute_height),alpha= 0.2, size = 1, col= \"darkgreen\") +\n  geom_line(data = df_2al, aes(x = x, y = elev_lowestmode), colour = \"red\", alpha = 0.4) +\n  geom_line(data = df_2al, aes(x = x, y = max_height), colour = \"black\", alpha = 0.4) +\n  ylab(\"Height (m)\") +\n  xlab(\"Distance along transect (m)\") +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(labels=c(0, 200, 400, 600, 800))\n\nggarrange(a,b, ncol = 2)\n\n\n\n\n\n\n\n#if(FALSE){\n#rh100metrics&lt;-gridStatsLevel2AM(level2AM = level2AM, func=mySetOfMetrics(rh100), res=0.005)\n\n# View maps\n\n#rh100maps&lt;-levelplot(rh100metrics,\n#                     layout=c(1, 4),\n#                     margin=FALSE,\n#                     xlab = \"Longitude (degree)\", ylab = \"Latitude (degree)\",\n#                     colorkey=list(\n#                       space='right',\n#                       labels=list(at=seq(0, 18, 2), font=4),\n#                       axis.line=list(col='black'),\n#                       width=1),\n#                     par.settings=list(\n#                       strip.border=list(col='gray'),\n#                       strip.background=list(col='gray'),\n#                       axis.line=list(col='gray')\n#                     ),\n#                     scales=list(draw=TRUE),\n#                     col.regions=viridis,\n#                     at=seq(0, 18, len=101),\n#                     names.attr=c(\"rh100 min\",\"rh100 max\",\"rh100 mean\", \"rh100 sd\"))\n#}\n\n\n#sp_2a &lt;- terra::project(sp_2a, \"epsg:27700\")\n\nsp_2a &lt;- sp_2a[sp_2a$quality_fl ==1,]\nsp_2a &lt;- sp_2a[sp_2a$degrade_fl &lt; 1,]\nsp_2a &lt;- sp_2a[sp_2a$sensitivit &gt; 0.9, ]\n\nsp_2a &lt;- buffer(sp_2a, 12.5) # adding on the radius of the beam for each shot\n\n#mapshot(\n  leaflet(sf::st_as_sf(v_mask)) %&gt;%\n  addTiles() %&gt;%\n  addPolygons( fillOpacity=0.1) %&gt;%\n  addPolygons(data=sf::st_as_sf(sp_2a),\n              color = \"red\") %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery) %&gt;%\n  addScaleBar(options = list(imperial = FALSE))#, \n\n\n\n\n  #file = here(\"data-output\", \"figures\", \"knepp_beams.png\" ))\n\n#include_graphics(here(\"data-output\", \"figures\", \"knepp_beams.png\"))\n\n# see https://lpdaac.usgs.gov/resources/e-learning/getting-started-gedi-l1b-version-2-data-python/\n# for plotting out sets of waveforms together\n\nThen also the issue with the geolocation problem means that the beams are not exact: rather there is a +/-10m geolocation error for each of the points. That means it could fall within a further 10m:\n\nsp_2a_err &lt;- buffer(sp_2a, 10) # adding on another 10m to show the extent of the error\n\n#mapshot(\n  leaflet(sf::st_as_sf(v_mask)) %&gt;%\n  addTiles() %&gt;%\n  addPolygons( fillOpacity=0.1) %&gt;%\n  addPolygons(data=sf::st_as_sf(sp_2a_err),\n              color = \"red\") %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery) %&gt;%\n  addScaleBar(options = list(imperial = FALSE))#, \n\n\n\n\n # file = here(\"data-output\", \"figures\", \"knepp_beams_10m_error.png\")\n#)\n\n#include_graphics(here(\"data-output\", \"figures\", \"knepp_beams_10m_error.png\"))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#level-2b",
    "href": "gedi_exploration.html#level-2b",
    "title": "2  GEDI data exploration",
    "section": "2.4 Level 2b:",
    "text": "2.4 Level 2b:\nThe level 2b data provides metrics calculated from earlier levels, namely plant area volume density, foliage height index, % cover and foliage clumping factor.Thes values are calculated in 5m increments rather than the percentile grouping used for the relative height profile. data\nProcessing: https://lpdaac.usgs.gov/resources/e-learning/getting-started-gedi-l2b-version-2-data-python/\nDetails: https://lpdaac.usgs.gov/products/gedi02_bv002/\nUser guide: https://lpdaac.usgs.gov/documents/998/GEDI02_UserGuide_V21.pdf\n\n2.4.1 Description of the canopy cover and vertical profile metrics:\nhttps://lpdaac.usgs.gov/documents/588/GEDI_FCCVPM_ATBD_v1.0.pdf\n\nPlant area index (PAI):\n\nLeaf Area Index (LAI) is one half of the total leaf area per unit ground surface. Closely linked to canopy cover through the gap distribution within the canopy. Plant Area Index (PAI) is closely related but incorporates all canopy structural elements (e.g. branch and trunk) in addition to leaves. The difference between PAI and LAI is often small in dense broadleaf forests (Tang 2012). The vertical profile is the vertical variation of PAI/LAI, which is closely related to foliage-height profiles. It is similar to a 3D canopy structure and can be used to describe growth patterns of forests at different successional stages (Parker 2004).\n\nPlant area volume density (pavd):\n\nThis is the vertical plant area volume density profile - the foliage profile: assuming a random distribution of canopy elements and constant leaf angle with height.\n\nFoliage height index (fhd):\n\nFHD measures complexirty of the canopy structure - also known as Shannon’s diversity index. High FHD values indicate high complexity.\n\n% Cover (cover):\n\nThis is the percentage of the ground covered by the vertical projection of canopy material (i.e. leaves, branches and stems only)\n\nCanopy cover profile (cover_z):\n\nThe horizontally- intercepted canopy elements at a given height (indicating that there is canopy cover there that will not be identified because it can’t be intercepted horizontally)\n\nFoliage clumping factor: (omega)\n\nBetween 0 and 1, the ratio of Pgap fora clumped canopy and Pgp for a random canopy of the same LAI. (Pgap = directional gap probability)\nWhat we want to do:\n\nidentify the different strata within the beam e.g. identify where the understory is and extract the PAI and PAVD for this, separate to the canopy.\n\n\n# preparing the pai and pavd dataframes:\n\ndf_2b &lt;- df_2b[df_2b$algorithmrun_flag == 1,]\ndf_2b &lt;- df_2b[df_2b$l2b_quality_flag == 1,]\n\ndf_pai &lt;- df_2b[,-grep(\"pavd\", names(df_2b))]\ndf_pai &lt;- df_pai %&gt;% gather(pai, value, grep(\"pai_\", names(df_pai)))\ndf_pai &lt;- df_pai[!(df_pai$value ==-9999),]\ndf_pai &lt;- df_pai[!(df_pai$value ==0),]\ndf_pai$pai_start &lt;- parse_number(df_pai$pai)\ndf_pai$rel_m &lt;- df_pai$pai_start + 2.5\ndf_pai$abs_m &lt;- df_pai$rel_m + df_pai$elev_lowestmode\n\ndf_pavd &lt;- df_2b[,-grep(\"pai\", names(df_2b))]\ndf_pavd &lt;- df_pavd %&gt;% gather(pavd, value, grep(\"pavd\", names(df_pavd)))\ndf_pavd &lt;- df_pavd[!(df_pavd$value ==-9999),]\ndf_pavd &lt;- df_pavd[!(df_pavd$value ==0),]\ndf_pavd$pavd_start &lt;- parse_number(df_pavd$pavd)\ndf_pavd$rel_m &lt;- df_pavd$pavd_start + 2.5\ndf_pavd$abs_m &lt;- df_pavd$rel_m + df_pavd$elev_lowestmode\n\n\n\n2.4.2 plotPAIProfile:\nadapted here as i have downloaded the data in a different fashion to the way developed in rGEDI due to not all beams being on at all times",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#pavd",
    "href": "gedi_exploration.html#pavd",
    "title": "2  GEDI data exploration",
    "section": "2.5 pavd",
    "text": "2.5 pavd\nvertical step size of plant area volume density is 5m PADV includes 30 steps in each shot describing the PAVD at height = step n to represent the PADV and the height elevation in the same figure, need to create a new height column",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#a-data",
    "href": "gedi_exploration.html#a-data",
    "title": "2  GEDI data exploration",
    "section": "2.6 4a data:",
    "text": "2.6 4a data:\n\n2.6.1 Extracting usable metrics from GEDI data:\nDue to the error in geolocation in the GEDI data, it isn’t possible to directly compare GEDI footprint data to ground truthed vegetation plots. As such, we will compare the GEDI footprint beams to a large footprint proxy derived from the drone lidar data. In this case, we are using the drone lidar as the highly accurate comparison and the GEDI data will be compared to this. We will assess how closely the large footprint GEDI beams correlate with the lidar derived large footprints for:\n\nmaximum height\nan understory complexity value\nvariation within the beam (foliage height diversity)\ncanopy cover fraction\nplant area index",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  }
]
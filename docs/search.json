[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RELOD ebook",
    "section": "",
    "text": "Preface\nRE-LOD - Testing the Limits Of remote sensing for Detecting forest and woodland structural and biomass REcovery\nProject team: Beth Raine, Lindsay Banin, Richard Broughton, Charles George, and Michael Tso (UKCEH)\nThis e-book provides additional markdown documents that contain code snippets to showcase some of the analysis discussed in the RE-LOD project report.\nAll of the content of this repository is licensed CC0.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "gedi_processing.html",
    "href": "gedi_processing.html",
    "title": "1  GEDI data processing",
    "section": "",
    "text": "1.1 How to access GEDI:\nGEDI data can be downloaded from Nasa’s Earthdata platform directly: https://search.earthdata.nasa.gov/search\nOn this platform you can specify the coordinates of your site of interest and download the GEDI passes that cover this particular region.\nFor GEDI 1B and 2B, when using NASA earthdata directly, you can crop the beam path to only download the section of interest, which saves a lot of space. However this functionality doesn’t seem to (yet) be available for the more recently released 4A datasets. In this code below, I have separately downloaded 1B and 2B data from the Earthdata platform, zipped the file including all beam passes and uploaded this to the minio platform. The first step is then to unzip these files.\nGEDI quick guide for how to download data directly from the Earthdata portal: https://lpdaac.usgs.gov/documents/635/GEDI_Quick_Guide.pdf\nYou can also download GEDI data through R using rGEDI (see below for explanation) and specifying the coordinates of your bounding box. However from my experience this will download the entire beam pass rather than the cropped region of interest, which generates very large files. I reccomend downloading data from earth data yourself using the crop function rather than using the download method included in rGEDI as this downloads the entire files which are huge (!) rather than just the cropped area.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>GEDI data processing</span>"
    ]
  },
  {
    "objectID": "gedi_processing.html#how-to-access-gedi",
    "href": "gedi_processing.html#how-to-access-gedi",
    "title": "1  GEDI data processing",
    "section": "",
    "text": "1.1.1 h5 file structures:\nGEDI data is downloaded in h5 file types. This is a Hierarchical data format that allows the storage of multidimensional arrays of data. As we are dealing with a separate dataset for every shot from GEDI, this makes it far easier to store such a large amount of data, however it is a little complicated to interact with if you are not familiar with this data format.\n\n\n1.1.2 Packages for GEDI in R:\nGEDI 1B, 2A and 2B data can be processed in R using rGEDI. The H5 structure of the GEDI data mean that they are not always simple to access and navigate through. The rGEDI package was developed to process Level 1 and 2 data (https://github.com/carlos-alberto-silva/rGEDI). This package can be useful for an introduction to how to navigate through the files and what you can access from them. However, this package is not flexible: it fails to open and navigate through the h5 files if you have a GEDI beam that had one or more lasers turned off during the flight. The GEDI4R package (https://github.com/VangiElia/GEDI4R, https://link.springer.com/article/10.1007/s12145-022-00915-3), complements the rGEDI package, has been developed to process level 4A data.\nThe code below assumes you have already downloaded the GEDI data for your region of interest from the Earthdata platform. In this example, we use the region of the Knepp estate in Sussex as an example. The code goes through the process of accessing the h5 datasets, pulling out the data for the region of interest and converting this into a more readily usable dataframe and shapefile format.\n\n#To install gedi download and processing packages:\n# devtools::install_git(\"https://github.com/carlos-alberto-silva/rGEDI\", dependencies = TRUE)\n# devtools::install_github(\"VangiElia/GEDI4R\")\n\nlibrary(rGEDI)\nlibrary(hdf5r)\nlibrary(terra)\nlibrary(lubridate)\nlibrary(GEDI4R)\n#library(rgdal)\nlibrary(raster)\nlibrary(hdf5r)\nlibrary(here)\nrm(list=ls())\n\n# bounding box of region\n# SW : 50.95,-0.399\n# NE : 50.99,-0.354\n\n\n# get shapefile for project area:\n\ns &lt;- vect(here(\"data-raw\", \"knepp_mask\", \"knepp_mask.shp\"))\ns &lt;- terra::project(s, \"EPSG: 4326\")\ns &lt;- fillHoles(s)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>GEDI data processing</span>"
    ]
  },
  {
    "objectID": "gedi_processing.html#identifying-files-for-download",
    "href": "gedi_processing.html#identifying-files-for-download",
    "title": "1  GEDI data processing",
    "section": "1.2 Identifying files for download",
    "text": "1.2 Identifying files for download\nThis can also be done on the Earthdata Nasa portal, which is better. It actually can crop to an area of interest. Here is the code of how it should be done using the rGEDI package, which I couldn’t get to work.\nGEDI naming conventions:\nGEDI01_B_2019110110221_O01997_03_T03335_02_005_01_V002.h5 indicates:\nGEDI01_B = Product Short Name\n2019110 = Julian Date of Acquisition in YYYYDDD\n110221 = Hours, Minutes, and Seconds of Acquisition (HHMMSS)\nO01997 = O = Orbit, 01997 = Orbit Number\n03 = Sub-Orbit Granule Number\nT03335 = T = Track, 033335 = Track Number\n02 = Positioning and Pointing Determination System (PPDS) type (00 is predict, 01 rapid, 02 and higher is final)\n005 = PGEVersion = SDPS Release Number\n01 = Granule Production Version\nV002 = Version Number\n.h5 = Data Format",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>GEDI data processing</span>"
    ]
  },
  {
    "objectID": "gedi_processing.html#using-gedi-data-in-datalabs",
    "href": "gedi_processing.html#using-gedi-data-in-datalabs",
    "title": "1  GEDI data processing",
    "section": "1.3 Using gedi data in datalabs:",
    "text": "1.3 Using gedi data in datalabs:\nNeed to put gedi data int the minio data store and then unzip gedi data downloaded from earth data:\n\n##############################\n# I cant get this rGEDI code to download just beams that fall within the bounding box area to work:\n\n# Study area boundary box coordinates\n\n#lr_lon &lt;- ext(s)$xmin \n#lr_lat &lt;- ext(s)$ymin\n#ul_lon &lt;- ext(s)$xmax\n#ul_lat &lt;- ext(s)$ymax\n\n# Specifying the date range\n#daterange=c(\"2021-01-01\",\"2022-07-22\")\n\n# Get path to GEDI data\n#gLevel1B&lt;-gedifinder(product=\"GEDI01_B\",ul_lat, ul_lon, lr_lat, lr_lon,version=\"002\",daterange=daterange)\n#gLevel2A&lt;-gedifinder(product=\"GEDI02_A\",ul_lat, ul_lon, lr_lat, lr_lon,version=\"002\",daterange=daterange)\n#gLevel2B&lt;-gedifinder(product=\"GEDI02_B\",ul_lat, ul_lon, lr_lat, lr_lon,version=\"002\",daterange=daterange)\n\n# returns thousands of beams which can't be right",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>GEDI data processing</span>"
    ]
  },
  {
    "objectID": "gedi_processing.html#level-1b-data",
    "href": "gedi_processing.html#level-1b-data",
    "title": "1  GEDI data processing",
    "section": "1.4 Level 1B data:",
    "text": "1.4 Level 1B data:\nLevel 1B GEDI data is the rawest form of data you can download. This includes the raw waveform data. This data level is good to download if you want to process it yourself and derive metrics that are not available in the more processed forms (Level2,3, or 4).\nUser guide: https://lpdaac.usgs.gov/documents/590/GEDIL01_User_Guide_V1.pdf\n#Steps to access level 1B GEDI h5 files, extract required information and save into a dataframe / shapefile are laid out below:\n#zipF&lt;- file.choose(“data-raw/knepp_mask.zip”) # lets you choose a file and save its file path in R (at least for windows) #outDir&lt;-“data-raw/gedi/rewild4a” # Define the folder where the zip file should be unzipped to #unzip(zipF,exdir=outDir)\n\n####\n# unzip GEDI 1B: this stage is only useful if you are working on datalabs and have had to add your GEDI data to the minio data platform as a zip file.\n# zipF&lt;- file.choose(\"path\") # lets you choose a file and save its file path in R (at least for windows)\n# outDir&lt;-\"set the path\" # Define the folder where the zip file should be unzipped to \n# unzip(zipF,exdir=outDir) \n\nbeams &lt;- c(\"BEAM0000\", \"BEAM0101\", \"BEAM1000\", \"BEAM0010\", \n           \"BEAM0011\", \"BEAM0110\", \"BEAM0001\", \"BEAM1011\")\n\nf_1b &lt;- list.files(here(\"data-raw\", \"gedi\", \"rewild1b\"))\n\n# navigate through the h5 files using the following terminology:\n#gedi_file &lt;- list.files(here(\"data-raw\", \"gedi\" \"rewild1b_01\",f_1b[i]))\n#file &lt;- paste0(f_1b[i], \"/\",gedi_file)\n\n#gedilevel1b &lt;- readLevel1B(level1Bpath = here(\"data-raw/gedi/knepp1b_01\", file))\n#level1b &lt;- gedilevel1b@h5\n#level1b[[paste0(\"BEAM0010/stale_return_flag\")]][]\n\n\n## this is a function to extract variables of interest from the h5 file. It is \n# adapted from the rGEDI package, which doesn't take into account that some \n# beams will not include data, and errors when you direclty apply it. \n# Here i have adapted this function to extract variables of interest, stale return\n# flag, elevatin_bin0, elevation_lastbin etc.\n\ngetLevel1BWF &lt;- function (level1b, v_sn) {\n  waveform &lt;- data.frame(matrix(ncol = 5, nrow= 0))\n  colnames(waveform) &lt;- c(\"rxwaveform\", \"elevation\", \"shot_number\", \"beam\", \"relwave\")\n  level1b &lt;- level1b@h5\n  for(j in 1:length(beams)){\n    i &lt;- beams[j]\n    \n    if(length(gedilevel1b@h5[[i]]$names)&gt;1) {\n      shot_number_i &lt;- level1b[[paste0(i, \"/shot_number\")]][]\n      for(l in 1:length(shot_number_i)){\n        shot_number = shot_number_i[l]\n        \n        shot_number_id &lt;- which(shot_number_i[] == shot_number)\n        stale_return_flag &lt;- level1b[[paste0(i, \"/stale_return_flag\")]][]\n        elevation_bin0 &lt;- level1b[[paste0(i, \"/geolocation/elevation_bin0\")]][]\n        elevation_lastbin &lt;- level1b[[paste0(i, \"/geolocation/elevation_lastbin\")]][]\n        rx_sample_count &lt;- level1b[[paste0(i, \"/rx_sample_count\")]][]\n        rx_sample_start_index &lt;- level1b[[paste0(i, \"/rx_sample_start_index\")]][]\n        rx_sample_start_index_n &lt;- rx_sample_start_index - min(rx_sample_start_index) + 1\n        rxwaveform_i &lt;- level1b[[paste0(i,\"/rxwaveform\")]][rx_sample_start_index_n[shot_number_id]:(rx_sample_start_index_n[shot_number_id] +  rx_sample_count[shot_number_id] - 1)]\n        rxwaveform_inorm &lt;- (rxwaveform_i - min(rxwaveform_i))/(max(rxwaveform_i) - \n                                                                  min(rxwaveform_i)) * 100\n        max &lt;- max(rxwaveform_i)\n        elevation_bin0_i &lt;- elevation_bin0[shot_number_id]\n        elevation_lastbin_i &lt;- elevation_lastbin[shot_number_id]\n        z = rev(seq(elevation_lastbin_i, elevation_bin0_i, (elevation_bin0_i - elevation_lastbin_i)/rx_sample_count[shot_number_id]))[-1]\n        waveform &lt;- rbind(waveform, data.table::data.table(rxwaveform = rxwaveform_i, \n                                                           elevation = z, \n                                                           shot_number = shot_number, \n                                                           beam = i,\n                                                           stale_return_flag = stale_return_flag,\n                                                           relwave = rxwaveform_i/ max))\n        \n      }}}\n  \n  return(waveform) \n}\n\n# extracting 1B data from h5 files:\n\n# create lists\nl_1b_spdf &lt;- list() # for a list of shapefiles\nl_1b_df &lt;- list() # for a list of dataframes\nl_1b_wf &lt;- list() # for the full waveform data\n\n# loop through each h5 file, extracting information and adding into the list of \n# shapefiles, dataframes and waveforms:\n\nfor(i in 1: length(f_1b)){\n  \n  gedi_file &lt;- list.files(here(\"data-raw\", \"gedi\", \"rewild1b\", f_1b[i]))\n  file &lt;- paste0(f_1b[i], \"/\",gedi_file)\n  \n  gedilevel1b &lt;- readLevel1B(level1Bpath = here(\"data-raw\", \"gedi\", \"rewild1b\", file))\n  \n  level1b &lt;-  gedilevel1b@h5 \n  \n  wf &lt;- getLevel1BWF(gedilevel1b)\n  \n  level1bGeo &lt;- getLevel1BGeo(level1b=gedilevel1b,\n                              select=c(\"elevation_bin0\",\n                                       \"elevation_lastbin\"))\n  level1bGeo$shot_number &lt;- paste0(level1bGeo$shot_number)\n  \n  #print(level1bGeo)\n  \n  # extract date info\n  yr &lt;- as.numeric(substring(gedi_file, first=20, last=23))\n  yday &lt;- as.numeric(substring(gedi_file, first=24, last=26))\n  hh &lt;- substring(gedi_file, first=27, last=28)\n  mm &lt;- substring(gedi_file, first=29, last=30)\n  ss &lt;- substring(gedi_file, first=31, last=32)\n  date_full &lt;- as.POSIXct(paste0(as.Date(yday, origin = paste0(yr,\"-01-01\")), \n                                 \" \",hh, \":\", mm, \":\", ss ), format=\"%Y-%m-%d %H:%M:%S\")\n  \n  level1bGeo$date &lt;- as.character(date_full)\n  \n  date &lt;- as.character(paste0(strftime(date_full, \"%d\"),\"_\",\n                              strftime(date_full, \"%m\"),\"_\",  yr,\"_\", hh, \"_\", mm, \"_\", ss))\n  \n  # Converting level1bGeo as data.table to SpatialPointsDataFrame\n  level1bGeo_spdf &lt;- vect(level1bGeo, geom=c(\"longitude_bin0\", \"latitude_bin0\"))\n  crs(level1bGeo_spdf) &lt;-  \"EPSG:4326\"\n  \n  #terra::writeVector(level1bGeo_spdf,paste0(\"bethtest/data/gedi_1b/GEDI_1B_\", date))\n  \n  l_1b_spdf[[i]] &lt;- level1bGeo_spdf\n  \n  l_1b_df[[i]] &lt;- level1bGeo\n  \n  l_1b_wf[[i]] &lt;- wf\n  \n}\n\nspdf_1b &lt;- do.call(rbind, l_1b_spdf)\ndf_1b &lt;- do.call(rbind, l_1b_df)\nwf_1b &lt;- do.call(rbind, l_1b_wf)\nwf_1b$shot_number &lt;- as.factor(wf_1b$shot_number)\n\nwriteVector(spdf_1b,here(\"data-output\", \"gedi\", \"g1b_full.shp\"), overwrite = TRUE)\nwrite.csv(df_1b,here(\"data-output\", \"gedi\", \"g1b_shot_dat.csv\"))\nwrite.csv(wf_1b,here(\"data-output\", \"gedi\", \"g1b_wave_dat.csv\"))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>GEDI data processing</span>"
    ]
  },
  {
    "objectID": "gedi_processing.html#level-2a",
    "href": "gedi_processing.html#level-2a",
    "title": "1  GEDI data processing",
    "section": "1.5 Level 2A",
    "text": "1.5 Level 2A\nThe GEDI02_A data product contains 156 layers for each of the eight beams, including ground elevation, canopy top height, relative return energy metrics (e.g., canopy vertical structure), and many other interpreted products from the return waveforms.\nAdditional information for the layers can be found in the GEDI Level 2A Dictionary: https://lpdaac.usgs.gov/products/gedi02_av002/\nThe code below lays out how to access these different metrics from the h5 files, extract them and compile them together for an area of interest.\n\nf_2a &lt;- c(list.files(here(\"data-raw\", \"gedi\",\"rewild2a\")))\n\n# dont want read mes\nf_2a &lt;- f_2a[-grep(\"README\", f_2a)]\nf_2a &lt;- paste0(\"data-raw/gedi/rewild2a/\", f_2a, \"/\")\n\nl_2a_sp &lt;- list()\nl_2a_df &lt;- list()\n\nfor(i in 1: length(f_2a)){\n  gedi_file &lt;- list.files(f_2a[i])\n  gedilevel2a &lt;- readLevel2A(level2Apath = paste0(f_2a[i], gedi_file))\n  \n  level2AM &lt;- getLevel2AM(gedilevel2a)\n  #head(level2AM[,c(\"beam\",\"shot_number\",\"elev_highestreturn\",\"elev_lowestmode\",\"rh100\")])\n  \n  # Converting shot_number as \"integer64\" to \"character\"\n  level2AM$shot_number &lt;- paste0(level2AM$shot_number)\n  \n  #compiling date\n  yr &lt;- as.numeric(substring(gedi_file, first=20, last=23))\n  yday &lt;- as.numeric(substring(gedi_file, first=24, last=26))\n  hh &lt;- substring(gedi_file, first=27, last=28)\n  mm &lt;- substring(gedi_file, first=29, last=30)\n  ss &lt;- substring(gedi_file, first=31, last=32)\n  date_full &lt;- as.POSIXct(paste0(as.Date(yday, origin = paste0(yr,\"-01-01\")), \" \",hh, \":\", mm, \":\", ss ), format=\"%Y-%m-%d %H:%M:%S\")\n  \n  level2AM$date &lt;- as.character(date_full)\n  \n  date &lt;- as.character(paste0(strftime(date_full, \"%d\"),\"_\", strftime(date_full, \"%m\"),\"_\",  yr,\"_\", hh, \"_\", mm, \"_\", ss))\n  \n  # Converting Elevation and Height Metrics as data.table to SpatialPointsDataFrame\n  level2AM_spdf &lt;- vect(level2AM, geom=c(\"lon_lowestmode\", \"lat_lowestmode\"))\n  \n  # Exporting Elevation and Height Metrics as ESRI Shapefile\n  #terra::writeVector(level2AM_spdf,paste0(\"bethtest/data/gedi_2a/GEDI_2A_\", substring(f_2a[1], first = 20, last = 21), \"_\", date))\n  \n  l_2a_sp[[i]] &lt;- level2AM_spdf \n  l_2a_df[[i]] &lt;- level2AM \n}\n\nsp_2a &lt;- do.call(rbind, l_2a_sp)\n\ndf_2a &lt;- do.call(rbind, l_2a_df)\n\nterra::writeVector(sp_2a, here(\"data-output\", \"gedi\", \"g2a_full.shp\"), overwrite = TRUE)\nwrite.csv(df_2a, here(\"data-output\", \"gedi\", \"g2a_full.csv\"))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>GEDI data processing</span>"
    ]
  },
  {
    "objectID": "gedi_processing.html#level-2b",
    "href": "gedi_processing.html#level-2b",
    "title": "1  GEDI data processing",
    "section": "1.6 Level 2B:",
    "text": "1.6 Level 2B:\nFor 2b you cant use the functions defined in rGEDI directly: something about not all of the beams being detected in every pass. Have 5 - 8 beams for each one S this produces a data frame that is pretty much the length of the number of shots from the study area\n\nf_2b &lt;- paste0(\"data-raw/gedi/rewild2b/\", \n               list.files(here(\"data-raw\", \"gedi\", \"rewild2b\")))\n\nbeams &lt;- c(\"BEAM0000\", \"BEAM0101\", \"BEAM1000\", \"BEAM0010\", \n           \"BEAM0011\", \"BEAM0110\", \"BEAM0001\", \"BEAM1011\")\n\n\nfor(i in 1:length(f_2b)){\n  \n  file &lt;- paste0(f_2b[i],\"/\", list.files(f_2b[i]))\n  gedi2 &lt;- readLevel2B(level2Bpath = file)\n  \n  for(j in 1:length(beams)){\n    \n    b &lt;- beams[j]\n    if(length(gedi2@h5[[b]]$names)&gt;1){\n      \n      level2b_i &lt;- gedi2@h5[[b]]\n      \n      # this is pulling out what happens in getLevel2BPAIProfile and\n      # getLevel2BPAVDProfile\n      \n      m &lt;- data.table::data.table(beam &lt;- rep(b, length(level2b_i[[\"shot_number\"]][])), \n                                  shot_number = level2b_i[[\"shot_number\"]][], \n                                  algorithmrun_flag = level2b_i[[\"algorithmrun_flag\"]][], \n                                  l2b_quality_flag = level2b_i[[\"l2b_quality_flag\"]][], \n                                  delta_time = level2b_i[[\"geolocation/delta_time\"]][], \n                                  lat_lowestmode = level2b_i[[\"geolocation/lat_lowestmode\"]][], \n                                  lon_lowestmode = level2b_i[[\"geolocation/lon_lowestmode\"]][], \n                                  elev_highestreturn = level2b_i[[\"geolocation/elev_highestreturn\"]][], \n                                  elev_lowestmode = level2b_i[[\"geolocation/elev_lowestmode\"]][], \n                                  height_lastbin = level2b_i[[\"geolocation/height_lastbin\"]][], \n                                  height_bin0 = level2b_i[[\"geolocation/height_bin0\"]][],\n                                  ## DTM = level2b_i[[\"digital_elevaion_model\"]][], # new\n                                  ##  srtm = level2b_i[[\"digital_elevation_model_srtm\"]] # new\n                                  cover = level2b_i[[\"cover\"]][],\n                                  pai = level2b_i[[\"pai\"]][],\n                                  omega = level2b_i[[\"omega\"]][],\n                                  fhd_normal = level2b_i[[\"fhd_normal\"]][],\n                                  pai_z = t(level2b_i[[\"pai_z\"]][, 1:level2b_i[[\"pai_z\"]]$dims[2]]),\n                                  pavd_z = t(level2b_i[[\"pavd_z\"]][, 1:level2b_i[[\"pavd_z\"]]$dims[2]]))\n      \n      colnames(m) &lt;- c(\"beam\", \"shot_number\", \"algorithmrun_flag\", \n                       \"l2b_quality_flag\", \"delta_time\", \"lat_lowestmode\", \n                       \"lon_lowestmode\", \"elev_highestreturn\", \"elev_lowestmode\", \n                       \"height_lastbin\", \"height_bin0\", \"cover\", \"pai\", \"omega\", \"fhd_normal\",\n                       paste0(\"pai_z\", seq(0, 30 * 5, 5)[-31], \n                              \"_\", seq(5, 30 * 5, 5), \"m\"),\n                       paste0(\"pavd_z\", seq(0, 30 * 5, 5)[-31], \n                              \"_\", seq(5, 30 * 5, 5), \"m\")) \n      \n      if(i ==1){\n        df_BVPM &lt;- m\n      }else{\n        df_BVPM &lt;- rbind(df_BVPM, m)\n        \n      }\n    }\n    \n  }\n  \n}\n\ndf_BVPM$shot_number &lt;- as.character(df_BVPM$shot_number)\ndf_BVPM_s &lt;- df_BVPM[df_BVPM$l2b_quality_flag ==1,]\n\nm &lt;- vect(df_BVPM, geom=c(\"lon_lowestmode\", \"lat_lowestmode\"))\nplot(m)\n\nms &lt;- vect(df_BVPM_s, geom=c(\"lon_lowestmode\", \"lat_lowestmode\"))\nplot(ms)\n\n# R has a 10 character limit for colnames in shapefiles so saving as df too. \n\nwrite.csv(df_BVPM_s, here(\"data-output\", \"gedi\", \"g2b_QC.csv\"))\nwriteVector(m, here(\"data-output\", \"gedi\", \"g2b_full.shp\"), overwrite = TRUE)\nwriteVector(ms, here(\"data-output\", \"gedi\", \"g2b_QC.shp\"), overwrite = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>GEDI data processing</span>"
    ]
  },
  {
    "objectID": "gedi_processing.html#level-4",
    "href": "gedi_processing.html#level-4",
    "title": "1  GEDI data processing",
    "section": "1.7 Level 4:",
    "text": "1.7 Level 4:\nWe aren’t going to explore the level 3 data here as that is just gridded 1km products from the 2b data. The level 4 data is the most highly processed data products, including aboveground biomass estimates.\n\n#outdir &lt;- here(\"data-raw\", \"gedi\", \"knepp4a\")\n##Get the list of all files available for the study area in the period selected,\n#using just_path = T\n#lr_lon &lt;- ext(s)$xmin \n#lr_lat &lt;- ext(s)$ymin\n#ul_lon &lt;- ext(s)$xmax\n#ul_lat &lt;- ext(s)$ymax\n\n#Get the list of all files available for the study area in the period selected,\n#using just_path = T\n#file_path &lt;- l4_download(\n#  ul_lat,\n#  lr_lat,\n#  ul_lon,\n#  lr_lon,\n#  outdir = outdir,\n#  from = \"2020-01-01\",\n#  to = \"2022-07-20\",\n#  just_path = T\n#)\n\n# this is very time consuming\n#download files\n#file_download &lt;- l4_download(\n#  ul_lat,\n#  lr_lat,\n#  ul_lon,\n#  lr_lon,\n#  ncore = parallel::detectCores()-1,\n#  outdir = outdir,\n#  from = \"2020-01-01\",\n#  to = \"2022-07-20\",\n#  just_path = F\n#  #subset=1:4\n#)\n\n\n#### reading:\nl &lt;- list.files(here(\"data-raw\", \"gedi\", \"rewild4a\"))\nl &lt;- paste0(\"data-raw/gedi/rewild4a/\", l)\n\n#list all dataset in h5 file\ndataname &lt;- l4_getmulti(l[[1]],just_colnames = T)\nhead(dataname, 183) # has 183 entries\n\n#read all footprint and merge them together.\n#!! this will use all CPUs available unless you specify otherwise!!\n\n#gediL4_path &lt;- l4_getmulti(l,merge=T, ncore =3)\n\n#select other columns to add to the default output.\n#if columns are already present in the default output they will be dropped\ncol &lt;-\n  c(\"land_cover_data/leaf_off_flag\",\n    \"agbd_pi_lower\",\n    \"agbd_pi_upper\",\n    \"lat_lowestmode\",\n    \"lon_lowestmode\",\n    \"land_cover_data/landsat_treecover\",        \n    \"land_cover_data/landsat_water_persistence\",\n    \"land_cover_data/leaf_off_doy\", \n    \"land_cover_data/leaf_on_cycle\",            \n    \"land_cover_data/leaf_on_doy\",\n    \"land_cover_data/pft_class\",                \n    \"land_cover_data/region_class\",\n    \"land_cover_data/shot_number\",              \n    \"land_cover_data/urban_focal_window_size\" ,\n    \"land_cover_data/urban_proportion\",  \n    \"agbd\"#this will be dropped as it is already included by default in the output.\n  )\n#get level 4 data with the user defined column binded and with the source path of each observation\n#with source=T a column with the source path for each observation will be added\ngediL4 &lt;- l4_getmulti(l,add_col = col,source=T, merge = T, ncore= 2)\n\n### CLIPPING:\n\n# Clipping using shapefile\n\nclipped &lt;- l4_clip(gediL4,clip=s,usegeometry = F)\n\n# save as csv\nwrite.csv(clipped, here(\"data-output\", \"gedi\", \"4a_gedi_knepp.csv\"))\n\n# saving output\nt &lt;- vect(clipped, geom=c(\"lon_lowestmode\",\"lat_lowestmode\"))\n\nwriteVector(t, here(\"data-output\", \"gedi\", \"GEDI_4A_all.shp\"))\n\nLevel 4b data is the 1km gridded estimates, this is a product extrapolated from the beam-level data. The data is provided in a standard .tif file so it is easier to process than the other level GEDI products.\nFor our example of the Knepp estate, this data isn’t particuarly meaningful.\n\n###############################################################################\n### 4B: this is gridded to the 1km square so it doesn't show much in this particular example \n\n#list.files(here(\"data\", \"gedi\", \"gedi_4b\", \"GEDI_L4B_Gridded_Biomass_2017\", \"data\")\n#           g4b &lt;- rast(here(\"data\", \"gedi\",\"gedi_4b\", \"GEDI_L4B_Gridded_Biomass_2017\", \"data\", #\"GEDI04_B_MW019MW138_02_002_05_R01000M_MU.tif\")\n\n#                      s &lt;- vect(\"data/gedi/knepp_outline.shp\")\n#                       s &lt;- terra::project(s, \"epsg:4326\")#  \"+proj=longlat +datum=WGS84\"\n#                       \n#                       g4b &lt;- project(g4b, \"EPSG:4326\") # currently as lat long\n#                       subset_4b &lt;- crop(g4b, ext(s))\n#                       plot(subset_4b)\n#                       \n#                       terra::writeRaster(subset_4b, here(\"data\", \"gedi\" , \"gedi_4b\", \"GEDI_4b_knepp.tif\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>GEDI data processing</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html",
    "href": "gedi_exploration.html",
    "title": "2  GEDI data exploration",
    "section": "",
    "text": "2.1 GEDI data products:\nMore detail on the data type can be found on the GEDI website (https://gedi.umd.edu/data/products/), but a brief summary is as follows:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#gedi-data-products",
    "href": "gedi_exploration.html#gedi-data-products",
    "title": "2  GEDI data exploration",
    "section": "",
    "text": "Level 1A data is not available for download as it is the completely raw waveform.\nLevel 1B data is the location of each of the waveforms\nLevel 2B data includes canopy cover fraction, canopy cover profile, leaf area index and leaf area index profile\nLevel 3 data (not explored here) gives gridded metrics of the level 2 data at a 1x1km resolution globally.\nLevel 4A gives footprint level aboveground biomass. See Dubayah (2022 - doi:10.1088/1748-9326/ac8694)\nLevel 4B gives a gridded metric of the level 4A data, at a 1x1km resolution globally.\n\n\n2.1.1 Interpreting GEDI data:\nThe GEDI lidar fires shots from 8 beams on the satellite at regular spaced intervals. By the time the shots reach earth, they have a 25m radius. The reflectance from the shots are collected by the satellite. This gives us a 3D imprint of the 25m footprint that the shot has reached. As such, we don’t get detail about the exact positioning of objects on the ground, but rather we get a profile of heights. From this it is possible to calculate additional metrics such as the ground level, canopy height, complexity etc.\n\n\n2.1.2 What is the difference between the beams?\nhttps://forum.earthdata.nasa.gov/viewtopic.php?t=756\nCoverage beams: 0000, 0001, 0010, 0011\nFull power beam: 0101, 0110, 1000, 1011\nGEDI coverage beams (beams 0000, 0001, 0010, and 0011) were designed to penetrate canopies of up to 95% canopy cover under “average” conditions. For this reason, it is recommended to preference the GEDI full power beams in cases of dense vegetation.\nStudies have shown that full power beams are more accurate at estimating canopy height in tropical forests (Lahssini (2022), and should be used, together with quality control for high sensitivity (&gt;0.98) shots only.\n\n\n2.1.3 Processing GEDI data\nThe H5 structure of the GEDI data mean that they are not always simple to access and navigate through. The rGEDI package was developed to process Level 1 and 2 data (https://github.com/carlos-alberto-silva/rGEDI). This package can be useful for an introduction to how to navigate through the files and what you can access from them. However, this package is not flexible: it fails to open and navigate through the h5 files if you have a GEDI beam that had one or more lasers turned off during the flight. The figures it produces are not valid if you have any shots missing.\n\n\n2.1.4 This script:\nThis script opens GEDI beam data from April 2019 to May 2022 and goes through manipulating and using this data. It then compares the GEDI footprint data to the drone collected small footprint lidar pass from Knepp estate in 2021.\n\n\n2.1.5 ISSUES:\n\n2b plots assume beams are sequential with 60m distances between them: this is not the case as they are sampled from different time periods so this distance should be derived from the coordinates rather than a standard 60m\nMissing beams affects use of rGEDI download, opening h5 files and as a result the use of all other functions in rGEDI - Why are some beams missing? I think because at various times some beams are turned off for maintenance\nNeed to check: currently from the 1b data all we have is the location and shot number, want ideally to be able to carry out the quality control on the data at this level and then only pull through the ones we want in 2a/2b etc.\nQuality flagging of data for the 2b plots\nTODO: make sure all quality control is carried out in the data processing file before we get here, so the files are all clean and ready to use\n\n\n# packages\n# rGEDI requires hdf5r package, which requires the HDF5 Linux library. Run `sudo apt update` and then `sudo apt-get install libhdf5-dev` in the terminal for Linux or Mac\n\n#library(devtools)\n#devtools::install_git(\"https://github.com/carlos-alberto-silva/rGEDI\", dependencies = TRUE)\n#devtools::install_github(\"VangiElia/GEDI4R\")\n \n\nlibrary(rGEDI) # for processing gedi data\nlibrary(GEDI4R)\n# need to do like an , if not here install this package\nlibrary(terra) # for processing rasters\nlibrary(leaflet) # for producing plots with the ESRI baselayers\nlibrary(leafsync)# \nlibrary(rasterVis) #\nlibrary(viridis) # colour palettes\nlibrary(htmltools)\nlibrary(here) # relative filepaths\nlibrary(tidyverse) # data wrangling\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(ggpubr) # grouping ggplots\nlibrary(mapview) # plotting maps\nlibrary(knitr)\nlibrary(mapview) # follow this to work on DataLabs (PhantomJS): https://gist.github.com/julionc/7476620\nlibrary(webshot)\n\ntheme_set(theme_classic())\n\n# creating a world map for plotting\nworld &lt;- ne_countries(scale=\"medium\", returnclass=\"sf\")\nworld &lt;- sf::st_as_sf(world, coords=c(\"x\",\"y\"), crs = 27700, agr = \"constant\", remove = F)\n\n# outline of Knepp:\n\n#-0.376, -0.362, 50.97, 50.98\n#-0.3764441, -0.363777, 50.97191, 50.98188 \n#v &lt;- vect(\"POLYGON ((-0.376 50.97 , -0.376 50.98, -0.362 50.98,  -0.362 50.97))\")\n\n#v_mask &lt;- vect(here(\"data-raw\", \"knepp_rwild.shp\"))\n#v &lt;- vect(here(\"datasets/KneppWildVeg\", \"rewildedfields.shp\"))\n#v &lt;- terra::project(v, \"EPSG:4326\")\n\nv_mask &lt;- vect(here(\"data-raw\", \"knepp_mask\", \"knepp_mask.shp\"))\nv_mask &lt;- terra::project(v_mask, \"epsg:4326\")#  \"+proj=longlat +datum=WGS84\"\n\n# shape files of the shots:\nsp_1b &lt;- terra::vect(here(\"data-output/gedi/\", \"g1b_full.shp\"))\nsp_2a &lt;- terra::vect(here(\"data-output/gedi/\", \"g2a_full.shp\"))\nsp_2b &lt;- terra::vect(here(\"data-output/gedi/\", \"g2b_full.shp\"))\n\n# dataframes of the shot data:\n# be sure to read in the shot number as a character at this point otherwise it will default to numeric and cut off the end of the value\n\ndf_1b_wave &lt;- read.csv(here(\"data-output/gedi/\", \"g1b_wave_dat.csv\"),\n                       row.names = 1, colClasses=c(\"shot_number\" = \"character\"))\ndf_1b_shot &lt;- read.csv(here(\"data-output/gedi/\", \"g1b_shot_dat.csv\"), \n                       row.names = 1, colClasses=c(\"shot_number\" = \"character\"))\n\ndf_1b_shot$date &lt;- as.Date(df_1b_shot$date)\ndf_1b_shot &lt;- df_1b_shot[df_1b_shot$date &gt; as.Date(\"2021-05-01\"),]\ndf_1b_shot &lt;- df_1b_shot[df_1b_shot$date &lt; as.Date(\"2022-05-01\"),]\n\ndf_1b_wave &lt;- df_1b_wave[df_1b_wave$shot_number %in% df_1b_shot$shot_number,]\n\n#df_2a &lt;- read.csv(here(\"data-output/gedi/\", \"g2a_full.csv\"), \n#                  row.names = 1, colClasses = c(\"shot_number\" = \"character\"))\n#df_2b &lt;- as.data.frame(vect(here(\"data-output/gedi/\", \"g2b_QC.shp\")))\n                       \n### turn them into osgb from lat long: easier to interpret as metres\ncrs(sp_2a) &lt;- \"epsg:4326\"\nsp_2a &lt;- terra::mask(sp_2a, v_mask)\nsp_2a &lt;- terra::project(sp_2a, \"EPSG:27700\")\n\ncrs(sp_2b) &lt;- \"epsg:4326\"\nsp_2b &lt;- terra::mask(sp_2b, v_mask)\nsp_2b &lt;- terra::project(sp_2b, \"EPSG:27700\")\n\ndf_2a &lt;- as.data.frame(sp_2a, geom= \"XY\")\ndf_2b &lt;- as.data.frame(sp_2b, geom = \"XY\")\n\nnames(df_2a)[1:9] &lt;- c(\"beam\", \"shot_number\", \"degrade_flag\",\"quality_flag\",\n                       \"delta_time\", \"sensitivity\", \"solar_elevation\", \"elev_highestmode\",\n                       \"elev_lowestmode\")\nnames(df_2b) &lt;- c(\"beam\", \"shot_number\", \"algorithm\", \"l2b_quality\",\"delta_time\", \n                  \"elev_highestmode\", \"elev_lowestmode\", \"height_last\", \"height_bin\",\n                  \"cover\", \"pai\", \"omega\", \"fhd_normal\", \n                  paste0(\"pai_z\", seq(0,145, by = 5), \"_\",seq(0,145, by = 5)+5),\n                  paste0(\"pavd_z\", seq(0,145, by = 5), \"_\",seq(0,145, by = 5)+5),\n                  \"x\", \"y\")\n\n\n# creating a dataframe as a lookup table for the different beams\nbeam &lt;- c(\"BEAM0000\", \"BEAM0001\", \"BEAM0010\", \"BEAM0011\",\n          \"BEAM0101\", \"BEAM0110\", \"BEAM1000\", \"BEAM1011\")\n\nv_coverage &lt;- c(rep(\"coverage\", 4), rep(\"full\", 4))\ndf_beams &lt;- as.data.frame(cbind(beam, v_coverage))\n\n#shp_4a &lt;- terra::vect(\"GEDI/g4A_all.shp\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#level-1b",
    "href": "gedi_exploration.html#level-1b",
    "title": "2  GEDI data exploration",
    "section": "2.2 Level 1B",
    "text": "2.2 Level 1B\nProcessing information in python: https://lpdaac.usgs.gov/resources/e-learning/getting-started-gedi-l1b-version-2-data-python/\nUser manual: https://lpdaac.usgs.gov/documents/987/GEDI01B_User_Guide_V2.pdf\nData dictionary: https://lpdaac.usgs.gov/documents/981/gedi_l1b_dictionary_P003_v2.html\nThe level 1B data gives us the waveform information from each shot. This data format is useful if you want to derive your own metrics from the waveform, or extract specific information from the vertical height profile.\nI think that because this is the rawest form data you can download, it doesn’t have the same quality control metrics that you find in the level 2 products. The idea being that if you wanted to, you could design your own quality flag from the data rather than interpreting it from this.\n\n# plotting an individual waveform:\ndf_shot1 &lt;- df_1b_wave[df_1b_wave$shot_number == df_1b_wave$shot_number[1],]\n\nggplot(df_shot1, aes(x= elevation, y = rxwaveform)) +\n  geom_line(colour= \"red\") +\n  theme(legend.position = \"none\") +\n  ggtitle(\"Single shot waveform\")\n\n\n\n\n\n\n\ndim(df_shot1)\n\n[1] 737   6\n\n# we get 759 returns from one single shot showing the relative elevation",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#level-2a",
    "href": "gedi_exploration.html#level-2a",
    "title": "2  GEDI data exploration",
    "section": "2.3 Level 2A",
    "text": "2.3 Level 2A\nProcessing: https://lpdaac.usgs.gov/resources/e-learning/getting-started-gedi-l2a-version-2-data-python/\nDetails: https://lpdaac.usgs.gov/products/gedi02_bv002/\nUser guide: https://lpdaac.usgs.gov/documents/998/GEDI02_UserGuide_V21.pdf\nThis is the level 1B waveform grouped into bins of relative height at a 1% interval.\nHere we can use the relative height bins, together with the ground elevation (elev_lowestmode) to construct a canopy height model and a digital elevation model.\n\n2.3.1 Interpreting RH values:\nQuestion: why are there negative values in the rh?? https://lpdaac.usgs.gov/documents/986/GEDI02_UserGuide_V2.pdf\n“Relative Height is calculated by the following equation: elev_highestreturn - elev_lowestmode. The lower RH metrics (e.g., RH10) will often have negative values, particularly in low canopy cover conditions. This is because a relatively high fraction of the waveform energy is from the ground and below elev_lowestmode. For example, if the ground return contains 30% of the energy, then RH1 through 15 are likely to be below 0 since half of the ground energy from the ground return is below the center of the ground return, which is used to determine the mean ground elevation in the footprint (elev_lowestmode). The RH metrics are intended for vegetated surfaces. Results over bare/water surfaces are still valid but may present some confusing results. See Section 6 of the Level 2 User Guide for more detailed information.”\n\n# Quality control:\n# want quality flag to be 1\n# degrade flag &lt; 1\n# sensitivity over 0.95\n# best to use data collected at night (solar_elevation &lt;0)\n# also want to use data that has a quality flag of 1\n\ndf_2a &lt;- df_2a[df_2a$quality_flag ==1,]\ndf_2a &lt;- df_2a[df_2a$degrade_flag &lt; 1,]\ndf_2a &lt;- df_2a[df_2a$sensitivity &gt; 0.9, ] #sufficient for over land\ndf_2a &lt;- df_2a[df_2a$shot_number %in% df_1b_shot$shot_number,]\n#df_2a &lt;- df_2a[df_2a$sensitivity &gt; 0.95, ] #better for some conditions e.g. dense forest\n\na &lt;- ggplot(df_2a, aes(x= x, y = rh100)) +\n  geom_point(alpha= 0.2)  +\n  geom_line(alpha = 0.2) +\n  theme(legend.position = \"none\") +\n  ylab(\"Relative elevation (m)\") +\n  xlab(\"Distance along transect (m)\") +\n  scale_x_continuous(labels=c(0, 200, 400, 600, 800)) +\n  ggtitle(\"Canopy height model\")\n\nb &lt;- ggplot(df_2a, aes(x= x, y = elev_lowestmode)) +\n  geom_point(alpha= 0.2)  +\n  geom_line(alpha = 0.2) +\n  theme(legend.position = \"none\") +\n  ylab(\"Relative elevation (m)\") +\n  xlab(\"Distance along transect (m)\") +\n  scale_x_continuous(labels=c(0, 200, 400, 600, 800)) +\n  ggtitle(\"Digital elevation model\")\n\nggarrange(a,b, ncol=2)\n\n\n\n\n\n\n\n# this is the digital elevation model\ndf_2al &lt;- df_2a %&gt;% gather(class, rel_height, grep(\"rh\", names(df_2a)))\ndf_2al$absolute_height &lt;- df_2al$elev_lowestmode + df_2al$rel_height\ndf_2al &lt;- df_2al[df_2al$rel_height &gt;0,]\ndf_2a$max_height &lt;- df_2a$rh100 + df_2a$elev_lowestmode\ndf_2al &lt;- left_join(df_2al, df_2a[,c(\"shot_number\", \"max_height\")], by= \"shot_number\")\n\na &lt;- ggplot(df_2al, aes(x= x, y = rel_height)) +\n  geom_point(alpha= 0.2, size = 1, col= \"darkgreen\") +\n  ylab(\"Relative elevation (m)\") +\n  xlab(\"Distance along transect (m)\") +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(labels=c(0, 200, 400, 600, 800))\n\nb &lt;- ggplot() +\n  geom_point(data = df_2al, aes(x= x, y = absolute_height),alpha= 0.2, size = 1, col= \"darkgreen\") +\n  geom_line(data = df_2al, aes(x = x, y = elev_lowestmode), colour = \"red\", alpha = 0.4) +\n  geom_line(data = df_2al, aes(x = x, y = max_height), colour = \"black\", alpha = 0.4) +\n  ylab(\"Height (m)\") +\n  xlab(\"Distance along transect (m)\") +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(labels=c(0, 200, 400, 600, 800))\n\nggarrange(a,b, ncol = 2)\n\n\n\n\n\n\n\n#if(FALSE){\n#rh100metrics&lt;-gridStatsLevel2AM(level2AM = level2AM, func=mySetOfMetrics(rh100), res=0.005)\n\n# View maps\n\n#rh100maps&lt;-levelplot(rh100metrics,\n#                     layout=c(1, 4),\n#                     margin=FALSE,\n#                     xlab = \"Longitude (degree)\", ylab = \"Latitude (degree)\",\n#                     colorkey=list(\n#                       space='right',\n#                       labels=list(at=seq(0, 18, 2), font=4),\n#                       axis.line=list(col='black'),\n#                       width=1),\n#                     par.settings=list(\n#                       strip.border=list(col='gray'),\n#                       strip.background=list(col='gray'),\n#                       axis.line=list(col='gray')\n#                     ),\n#                     scales=list(draw=TRUE),\n#                     col.regions=viridis,\n#                     at=seq(0, 18, len=101),\n#                     names.attr=c(\"rh100 min\",\"rh100 max\",\"rh100 mean\", \"rh100 sd\"))\n#}\n\n\nsp_2a &lt;- terra::project(sp_2a, \"epsg:27700\")\n\nsp_2a &lt;- sp_2a[sp_2a$quality_fl ==1,]\nsp_2a &lt;- sp_2a[sp_2a$degrade_fl &lt; 1,]\nsp_2a &lt;- sp_2a[sp_2a$sensitivit &gt; 0.9, ]\n\nsp_2a &lt;- buffer(sp_2a, 12.5) # adding on the radius of the beam for each shot\n\n#mapshot(\n  leaflet(sf::st_as_sf(v_mask)) %&gt;%\n  addTiles() %&gt;%\n  addPolygons( fillOpacity=0.1) %&gt;%\n  addPolygons(data=sf::st_as_sf(sp_2a),\n              color = \"red\") %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery) %&gt;%\n  addScaleBar(options = list(imperial = FALSE))#, \n\n\n\n\n  #file = here(\"data-output\", \"figures\", \"knepp_beams.png\" ))\n\n#include_graphics(here(\"data-output\", \"figures\", \"knepp_beams.png\"))\n\n# see https://lpdaac.usgs.gov/resources/e-learning/getting-started-gedi-l1b-version-2-data-python/\n# for plotting out sets of waveforms together\n\nThen also the issue with the geolocation problem means that the beams are not exact: rather there is a +/-10m geolocation error for each of the points. That means it could fall within a further 10m:\n\nsp_2a_err &lt;- buffer(sp_2a, 10) # adding on another 10m to show the extent of the error\n\n#mapshot(\n  leaflet(sf::st_as_sf(v_mask)) %&gt;%\n  addTiles() %&gt;%\n  addPolygons( fillOpacity=0.1) %&gt;%\n  addPolygons(data=sf::st_as_sf(sp_2a_err),\n              color = \"red\") %&gt;%\n  addProviderTiles(providers$Esri.WorldImagery) %&gt;%\n  addScaleBar(options = list(imperial = FALSE))#, \n\n\n\n\n # file = here(\"data-output\", \"figures\", \"knepp_beams_10m_error.png\")\n#)\n\n#include_graphics(here(\"data-output\", \"figures\", \"knepp_beams_10m_error.png\"))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#level-2b",
    "href": "gedi_exploration.html#level-2b",
    "title": "2  GEDI data exploration",
    "section": "2.4 Level 2b:",
    "text": "2.4 Level 2b:\nThe level 2b data provides metrics calculated from earlier levels, namely plant area volume density, foliage height index, % cover and foliage clumping factor.Thes values are calculated in 5m increments rather than the percentile grouping used for the relative height profile. data\nProcessing: https://lpdaac.usgs.gov/resources/e-learning/getting-started-gedi-l2b-version-2-data-python/\nDetails: https://lpdaac.usgs.gov/products/gedi02_bv002/\nUser guide: https://lpdaac.usgs.gov/documents/998/GEDI02_UserGuide_V21.pdf\n\n2.4.1 Description of the canopy cover and vertical profile metrics:\nhttps://lpdaac.usgs.gov/documents/588/GEDI_FCCVPM_ATBD_v1.0.pdf\n\nPlant area index (PAI):\n\nLeaf Area Index (LAI) is one half of the total leaf area per unit ground surface. Closely linked to canopy cover through the gap distribution within the canopy. Plant Area Index (PAI) is closely related but incorporates all canopy structural elements (e.g. branch and trunk) in addition to leaves. The difference between PAI and LAI is often small in dense broadleaf forests (Tang 2012). The vertical profile is the vertical variation of PAI/LAI, which is closely related to foliage-height profiles. It is similar to a 3D canopy structure and can be used to describe growth patterns of forests at different successional stages (Parker 2004).\n\nPlant area volume density (pavd):\n\nThis is the vertical plant area volume density profile - the foliage profile: assuming a random distribution of canopy elements and constant leaf angle with height.\n\nFoliage height index (fhd):\n\nFHD measures complexirty of the canopy structure - also known as Shannon’s diversity index. High FHD values indicate high complexity.\n\n% Cover (cover):\n\nThis is the percentage of the ground covered by the vertical projection of canopy material (i.e. leaves, branches and stems only)\n\nCanopy cover profile (cover_z):\n\nThe horizontally- intercepted canopy elements at a given height (indicating that there is canopy cover there that will not be identified because it can’t be intercepted horizontally)\n\nFoliage clumping factor: (omega)\n\nBetween 0 and 1, the ratio of Pgap fora clumped canopy and Pgp for a random canopy of the same LAI. (Pgap = directional gap probability)\nWhat we want to do:\n\nidentify the different strata within the beam e.g. identify where the understory is and extract the PAI and PAVD for this, separate to the canopy.\n\n\n# preparing the pai and pavd dataframes:\n\ndf_2b &lt;- df_2b[df_2b$algorithmrun_flag == 1,]\ndf_2b &lt;- df_2b[df_2b$l2b_quality_flag == 1,]\n\ndf_pai &lt;- df_2b[,-grep(\"pavd\", names(df_2b))]\ndf_pai &lt;- df_pai %&gt;% gather(pai, value, grep(\"pai_\", names(df_pai)))\ndf_pai &lt;- df_pai[!(df_pai$value ==-9999),]\ndf_pai &lt;- df_pai[!(df_pai$value ==0),]\ndf_pai$pai_start &lt;- parse_number(df_pai$pai)\ndf_pai$rel_m &lt;- df_pai$pai_start + 2.5\ndf_pai$abs_m &lt;- df_pai$rel_m + df_pai$elev_lowestmode\n\ndf_pavd &lt;- df_2b[,-grep(\"pai\", names(df_2b))]\ndf_pavd &lt;- df_pavd %&gt;% gather(pavd, value, grep(\"pavd\", names(df_pavd)))\ndf_pavd &lt;- df_pavd[!(df_pavd$value ==-9999),]\ndf_pavd &lt;- df_pavd[!(df_pavd$value ==0),]\ndf_pavd$pavd_start &lt;- parse_number(df_pavd$pavd)\ndf_pavd$rel_m &lt;- df_pavd$pavd_start + 2.5\ndf_pavd$abs_m &lt;- df_pavd$rel_m + df_pavd$elev_lowestmode\n\n\n\n2.4.2 plotPAIProfile:\nadapted here as i have downloaded the data in a different fashion to the way developed in rGEDI due to not all beams being on at all times",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#pavd",
    "href": "gedi_exploration.html#pavd",
    "title": "2  GEDI data exploration",
    "section": "2.5 pavd",
    "text": "2.5 pavd\nvertical step size of plant area volume density is 5m PADV includes 30 steps in each shot describing the PAVD at height = step n to represent the PADV and the height elevation in the same figure, need to create a new height column",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "gedi_exploration.html#a-data",
    "href": "gedi_exploration.html#a-data",
    "title": "2  GEDI data exploration",
    "section": "2.6 4a data:",
    "text": "2.6 4a data:\n\n2.6.1 Extracting usable metrics from GEDI data:\nDue to the error in geolocation in the GEDI data, it isn’t possible to directly compare GEDI footprint data to ground truthed vegetation plots. As such, we will compare the GEDI footprint beams to a large footprint proxy derived from the drone lidar data. In this case, we are using the drone lidar as the highly accurate comparison and the GEDI data will be compared to this. We will assess how closely the large footprint GEDI beams correlate with the lidar derived large footprints for:\n\nmaximum height\nan understory complexity value\nvariation within the beam (foliage height diversity)\ncanopy cover fraction\nplant area index",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GEDI data exploration</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html",
    "href": "lidar_processing.html",
    "title": "3  LiDAR data processing",
    "section": "",
    "text": "3.1 Pre-processing steps\nThis R script takes a pre-processed point cloud from a UAV drone pass file .laz or .las. It reads the files in using the LAStools package, which is a separate executable programme which can be implemented through R. .laz files are zipped versions of .las files. They can be good for storing large amounts of data, however they do take time to unzip each time you use them so are not always better than .las files for storing drone data.\nA really useful place to start is the lidR package which has detailed tutorials: lidR book: https://r-lidar.github.io/lidRbook/index.html This lays out a lot of the preprocessing steps:\nreadLAS(filter = “-help”)\ncan thin the dataset before you read it filter = “xyz” removes all but the point cloud data filter = “-keep_first” : commonly used in forestry filter = “-keep_every_nth x” used for thinning out the point cloud to reduce the size",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html#pre-processing-steps",
    "href": "lidar_processing.html#pre-processing-steps",
    "title": "3  LiDAR data processing",
    "section": "",
    "text": "3.1.1 Thinning and filtering:\n\n# Load a LAScatalog instead of a LAS file\n## try reading the full las file and thin it:\n\n# this is a big file and it does take a while to load even when thinned\n# try thin_with_grid\nlas_first &lt;- readLAS(here(\"data-raw\", \"lidar\", \"Knepp_points_processed_merged.las\"),\n             filter = \"-keep_first\")\nwriteLAS(las_first, here(\"data-raw\", \"lidar\", \"knepp_full_keep_first.las\"))\n# make sure you have the most up to date version of lidR\n\n# this is one every 20cm - this is still very high resolution and probably enough for processing\nlas_100th &lt;- lidR::readLAS(here(\"data-raw\", \"lidar\" \"Knepp_points_processed_merged.las\"), \n                    filter = \"-keep_every_nth 100\")\n\nwriteLAS(las_100th, here(\"data-output\", \"lidar_outputs\", \"knepp_full_thin_100.las\"))\n\nlas_10th &lt;- readLAS(here(\"data-raw\", \"lidar\", \"Knepp_points_processed_merged.las\"),\n               filter = \"-keep_every_nth 10\")\nwriteLAS(las_10th, here(\"data-raw\", \"lidar\", \"knepp_full_thin_10.las\"))\n\n\n\n3.1.2 Retiling:\nSplitting into smaller tiles for ease of processing\n\nctg &lt;- readLAScatalog(here(\"data-output\", \"lidar_outputs\", \"knepp_full_thin_100.las\"))\nopt_chunk_buffer(ctg) &lt;- 0\nopt_chunk_size(ctg) &lt;- 250\nopt_output_files(ctg) &lt;- paste0(\"data-output/lidar_outputs/las_cat_10\", \"/retile_{XLEFT}_{YBOTTOM}\")\nplot(ctg, chunk = TRUE)\ncatalog_retile(ctg)\n\nLoading in our .las file:\n\n# Process it like a LAS file\nctg &lt;- readLAScatalog(here(\"data-output/lidar_outputs/las_cat_100\"))\n\nlas &lt;- readLAS(ctg,filter = \"-drop_z_below 0\")\n\n#plot(las)\n\n\n\n3.1.3 Classifying the ground\nI think this had already been done in the original knepp point cloud. So this is redoing that as it isn’t always accurate. It includes pmf, csf and mcc for ground classification. ws = Sequence of windows sizes to be used in filtering ground returns. The values must be positive and in the same units as the point cloud (usually meters, occasionally feet).\nth = numeric. Sequence of threshold heights above the parameterized ground surface to be considered a ground return. The values must be positive and in the same units as the point cloud. Values used here as in “Estimating Forest Structure from UAV-Mounted LiDAR Point Cloud Using Machine Learning”\n\n# this is time consuming\n#ws &lt;- seq(0.5, 2.5, 3)\n#th &lt;- seq(0.1,0.5, length.out = length(ws))\n\n# this function extracts some default ws and th values to use from \n# the Zhang paper\n\np &lt;- util_makeZhangParam(\n  b = 2,\n  dh0 = 0.5,\n  dhmax = 3,\n  s = 1,\n  max_ws = 20,\n  exp = FALSE\n)\nlas &lt;- classify_ground(las, algorithm = pmf(ws = p$ws, th = p$th))\n\nMorphological filter: 4% (1 threads)\nMorphological filter: 5% (1 threads)\nMorphological filter: 6% (1 threads)\nMorphological filter: 7% (1 threads)\nMorphological filter: 8% (1 threads)\nMorphological filter: 9% (1 threads)\nMorphological filter: 10% (1 threads)\nMorphological filter: 11% (1 threads)\nMorphological filter: 12% (1 threads)\nMorphological filter: 13% (1 threads)\nMorphological filter: 14% (1 threads)\nMorphological filter: 15% (1 threads)\nMorphological filter: 16% (1 threads)\nMorphological filter: 17% (1 threads)\nMorphological filter: 18% (1 threads)\nMorphological filter: 19% (1 threads)\nMorphological filter: 20% (1 threads)\nMorphological filter: 21% (1 threads)\nMorphological filter: 22% (1 threads)\nMorphological filter: 23% (1 threads)\nMorphological filter: 24% (1 threads)\nMorphological filter: 25% (1 threads)\nMorphological filter: 26% (1 threads)\nMorphological filter: 27% (1 threads)\nMorphological filter: 28% (1 threads)\nMorphological filter: 29% (1 threads)\nMorphological filter: 30% (1 threads)\nMorphological filter: 31% (1 threads)\nMorphological filter: 32% (1 threads)\nMorphological filter: 33% (1 threads)\nMorphological filter: 34% (1 threads)\nMorphological filter: 35% (1 threads)\nMorphological filter: 36% (1 threads)\nMorphological filter: 37% (1 threads)\nMorphological filter: 38% (1 threads)\nMorphological filter: 39% (1 threads)\nMorphological filter: 40% (1 threads)\nMorphological filter: 41% (1 threads)\nMorphological filter: 42% (1 threads)\nMorphological filter: 43% (1 threads)\nMorphological filter: 44% (1 threads)\nMorphological filter: 45% (1 threads)\nMorphological filter: 46% (1 threads)\nMorphological filter: 47% (1 threads)\nMorphological filter: 48% (1 threads)\nMorphological filter: 49% (1 threads)\nMorphological filter: 50% (1 threads)\nMorphological filter: 51% (1 threads)\nMorphological filter: 52% (1 threads)\nMorphological filter: 53% (1 threads)\nMorphological filter: 54% (1 threads)\nMorphological filter: 55% (1 threads)\nMorphological filter: 56% (1 threads)\nMorphological filter: 57% (1 threads)\nMorphological filter: 58% (1 threads)\nMorphological filter: 59% (1 threads)\nMorphological filter: 60% (1 threads)\nMorphological filter: 61% (1 threads)\nMorphological filter: 62% (1 threads)\nMorphological filter: 63% (1 threads)\nMorphological filter: 64% (1 threads)\nMorphological filter: 65% (1 threads)\nMorphological filter: 66% (1 threads)\nMorphological filter: 67% (1 threads)\nMorphological filter: 68% (1 threads)\nMorphological filter: 69% (1 threads)\nMorphological filter: 70% (1 threads)\nMorphological filter: 71% (1 threads)\nMorphological filter: 72% (1 threads)\nMorphological filter: 73% (1 threads)\nMorphological filter: 74% (1 threads)\nMorphological filter: 75% (1 threads)\nMorphological filter: 76% (1 threads)\nMorphological filter: 77% (1 threads)\nMorphological filter: 78% (1 threads)\nMorphological filter: 79% (1 threads)\nMorphological filter: 80% (1 threads)\nMorphological filter: 81% (1 threads)\nMorphological filter: 82% (1 threads)\nMorphological filter: 83% (1 threads)\nMorphological filter: 84% (1 threads)\nMorphological filter: 85% (1 threads)\nMorphological filter: 86% (1 threads)\nMorphological filter: 87% (1 threads)\nMorphological filter: 88% (1 threads)\nMorphological filter: 89% (1 threads)\nMorphological filter: 90% (1 threads)\nMorphological filter: 91% (1 threads)\nMorphological filter: 92% (1 threads)\nMorphological filter: 93% (1 threads)\nMorphological filter: 94% (1 threads)\nMorphological filter: 95% (1 threads)\nMorphological filter: 96% (1 threads)\nMorphological filter: 97% (1 threads)\nMorphological filter: 98% (1 threads)\nMorphological filter: 99% (1 threads)\nMorphological filter: 3% (1 threads)\nMorphological filter: 4% (1 threads)\nMorphological filter: 5% (1 threads)\nMorphological filter: 6% (1 threads)\nMorphological filter: 7% (1 threads)\nMorphological filter: 8% (1 threads)\nMorphological filter: 9% (1 threads)\nMorphological filter: 10% (1 threads)\nMorphological filter: 11% (1 threads)\nMorphological filter: 12% (1 threads)\nMorphological filter: 13% (1 threads)\nMorphological filter: 14% (1 threads)\nMorphological filter: 15% (1 threads)\nMorphological filter: 16% (1 threads)\nMorphological filter: 17% (1 threads)\nMorphological filter: 18% (1 threads)\nMorphological filter: 19% (1 threads)\nMorphological filter: 20% (1 threads)\nMorphological filter: 21% (1 threads)\nMorphological filter: 22% (1 threads)\nMorphological filter: 23% (1 threads)\nMorphological filter: 24% (1 threads)\nMorphological filter: 25% (1 threads)\nMorphological filter: 26% (1 threads)\nMorphological filter: 27% (1 threads)\nMorphological filter: 28% (1 threads)\nMorphological filter: 29% (1 threads)\nMorphological filter: 30% (1 threads)\nMorphological filter: 31% (1 threads)\nMorphological filter: 32% (1 threads)\nMorphological filter: 33% (1 threads)\nMorphological filter: 34% (1 threads)\nMorphological filter: 35% (1 threads)\nMorphological filter: 36% (1 threads)\nMorphological filter: 37% (1 threads)\nMorphological filter: 38% (1 threads)\nMorphological filter: 39% (1 threads)\nMorphological filter: 40% (1 threads)\nMorphological filter: 41% (1 threads)\nMorphological filter: 42% (1 threads)\nMorphological filter: 43% (1 threads)\nMorphological filter: 44% (1 threads)\nMorphological filter: 45% (1 threads)\nMorphological filter: 46% (1 threads)\nMorphological filter: 47% (1 threads)\nMorphological filter: 48% (1 threads)\nMorphological filter: 49% (1 threads)\nMorphological filter: 50% (1 threads)\nMorphological filter: 51% (1 threads)\nMorphological filter: 52% (1 threads)\nMorphological filter: 53% (1 threads)\nMorphological filter: 54% (1 threads)\nMorphological filter: 55% (1 threads)\nMorphological filter: 56% (1 threads)\nMorphological filter: 57% (1 threads)\nMorphological filter: 58% (1 threads)\nMorphological filter: 59% (1 threads)\nMorphological filter: 60% (1 threads)\nMorphological filter: 61% (1 threads)\nMorphological filter: 62% (1 threads)\nMorphological filter: 63% (1 threads)\nMorphological filter: 64% (1 threads)\nMorphological filter: 65% (1 threads)\nMorphological filter: 66% (1 threads)\nMorphological filter: 67% (1 threads)\nMorphological filter: 68% (1 threads)\nMorphological filter: 69% (1 threads)\nMorphological filter: 70% (1 threads)\nMorphological filter: 71% (1 threads)\nMorphological filter: 72% (1 threads)\nMorphological filter: 73% (1 threads)\nMorphological filter: 74% (1 threads)\nMorphological filter: 75% (1 threads)\nMorphological filter: 76% (1 threads)\nMorphological filter: 77% (1 threads)\nMorphological filter: 78% (1 threads)\nMorphological filter: 79% (1 threads)\nMorphological filter: 80% (1 threads)\nMorphological filter: 81% (1 threads)\nMorphological filter: 82% (1 threads)\nMorphological filter: 83% (1 threads)\nMorphological filter: 84% (1 threads)\nMorphological filter: 85% (1 threads)\nMorphological filter: 86% (1 threads)\nMorphological filter: 87% (1 threads)\nMorphological filter: 88% (1 threads)\nMorphological filter: 89% (1 threads)\nMorphological filter: 90% (1 threads)\nMorphological filter: 91% (1 threads)\nMorphological filter: 92% (1 threads)\nMorphological filter: 93% (1 threads)\nMorphological filter: 94% (1 threads)\nMorphological filter: 95% (1 threads)\nMorphological filter: 96% (1 threads)\nMorphological filter: 97% (1 threads)\nMorphological filter: 98% (1 threads)\nMorphological filter: 99% (1 threads)\nMorphological filter: 2% (1 threads)\nMorphological filter: 3% (1 threads)\nMorphological filter: 4% (1 threads)\nMorphological filter: 5% (1 threads)\nMorphological filter: 6% (1 threads)\nMorphological filter: 7% (1 threads)\nMorphological filter: 8% (1 threads)\nMorphological filter: 9% (1 threads)\nMorphological filter: 10% (1 threads)\nMorphological filter: 11% (1 threads)\nMorphological filter: 12% (1 threads)\nMorphological filter: 13% (1 threads)\nMorphological filter: 14% (1 threads)\nMorphological filter: 15% (1 threads)\nMorphological filter: 16% (1 threads)\nMorphological filter: 17% (1 threads)\nMorphological filter: 18% (1 threads)\nMorphological filter: 19% (1 threads)\nMorphological filter: 20% (1 threads)\nMorphological filter: 21% (1 threads)\nMorphological filter: 22% (1 threads)\nMorphological filter: 23% (1 threads)\nMorphological filter: 24% (1 threads)\nMorphological filter: 25% (1 threads)\nMorphological filter: 26% (1 threads)\nMorphological filter: 27% (1 threads)\nMorphological filter: 28% (1 threads)\nMorphological filter: 29% (1 threads)\nMorphological filter: 30% (1 threads)\nMorphological filter: 31% (1 threads)\nMorphological filter: 32% (1 threads)\nMorphological filter: 33% (1 threads)\nMorphological filter: 34% (1 threads)\nMorphological filter: 35% (1 threads)\nMorphological filter: 36% (1 threads)\nMorphological filter: 37% (1 threads)\nMorphological filter: 38% (1 threads)\nMorphological filter: 39% (1 threads)\nMorphological filter: 40% (1 threads)\nMorphological filter: 41% (1 threads)\nMorphological filter: 42% (1 threads)\nMorphological filter: 43% (1 threads)\nMorphological filter: 44% (1 threads)\nMorphological filter: 45% (1 threads)\nMorphological filter: 46% (1 threads)\nMorphological filter: 47% (1 threads)\nMorphological filter: 48% (1 threads)\nMorphological filter: 49% (1 threads)\nMorphological filter: 50% (1 threads)\nMorphological filter: 51% (1 threads)\nMorphological filter: 52% (1 threads)\nMorphological filter: 53% (1 threads)\nMorphological filter: 54% (1 threads)\nMorphological filter: 55% (1 threads)\nMorphological filter: 56% (1 threads)\nMorphological filter: 57% (1 threads)\nMorphological filter: 58% (1 threads)\nMorphological filter: 59% (1 threads)\nMorphological filter: 60% (1 threads)\nMorphological filter: 61% (1 threads)\nMorphological filter: 62% (1 threads)\nMorphological filter: 63% (1 threads)\nMorphological filter: 64% (1 threads)\nMorphological filter: 65% (1 threads)\nMorphological filter: 66% (1 threads)\nMorphological filter: 67% (1 threads)\nMorphological filter: 68% (1 threads)\nMorphological filter: 69% (1 threads)\nMorphological filter: 70% (1 threads)\nMorphological filter: 71% (1 threads)\nMorphological filter: 72% (1 threads)\nMorphological filter: 73% (1 threads)\nMorphological filter: 74% (1 threads)\nMorphological filter: 75% (1 threads)\nMorphological filter: 76% (1 threads)\nMorphological filter: 77% (1 threads)\nMorphological filter: 78% (1 threads)\nMorphological filter: 79% (1 threads)\nMorphological filter: 80% (1 threads)\nMorphological filter: 81% (1 threads)\nMorphological filter: 82% (1 threads)\nMorphological filter: 83% (1 threads)\nMorphological filter: 84% (1 threads)\nMorphological filter: 85% (1 threads)\nMorphological filter: 86% (1 threads)\nMorphological filter: 87% (1 threads)\nMorphological filter: 88% (1 threads)\nMorphological filter: 89% (1 threads)\nMorphological filter: 90% (1 threads)\nMorphological filter: 91% (1 threads)\nMorphological filter: 92% (1 threads)\nMorphological filter: 93% (1 threads)\nMorphological filter: 94% (1 threads)\nMorphological filter: 95% (1 threads)\nMorphological filter: 96% (1 threads)\nMorphological filter: 97% (1 threads)\nMorphological filter: 98% (1 threads)\nMorphological filter: 99% (1 threads)\nMorphological filter: 1% (1 threads)\nMorphological filter: 2% (1 threads)\nMorphological filter: 3% (1 threads)\nMorphological filter: 4% (1 threads)\nMorphological filter: 5% (1 threads)\nMorphological filter: 6% (1 threads)\nMorphological filter: 7% (1 threads)\nMorphological filter: 8% (1 threads)\nMorphological filter: 9% (1 threads)\nMorphological filter: 10% (1 threads)\nMorphological filter: 11% (1 threads)\nMorphological filter: 12% (1 threads)\nMorphological filter: 13% (1 threads)\nMorphological filter: 14% (1 threads)\nMorphological filter: 15% (1 threads)\nMorphological filter: 16% (1 threads)\nMorphological filter: 17% (1 threads)\nMorphological filter: 18% (1 threads)\nMorphological filter: 19% (1 threads)\nMorphological filter: 20% (1 threads)\nMorphological filter: 21% (1 threads)\nMorphological filter: 22% (1 threads)\nMorphological filter: 23% (1 threads)\nMorphological filter: 24% (1 threads)\nMorphological filter: 25% (1 threads)\nMorphological filter: 26% (1 threads)\nMorphological filter: 27% (1 threads)\nMorphological filter: 28% (1 threads)\nMorphological filter: 29% (1 threads)\nMorphological filter: 30% (1 threads)\nMorphological filter: 31% (1 threads)\nMorphological filter: 32% (1 threads)\nMorphological filter: 33% (1 threads)\nMorphological filter: 34% (1 threads)\nMorphological filter: 35% (1 threads)\nMorphological filter: 36% (1 threads)\nMorphological filter: 37% (1 threads)\nMorphological filter: 38% (1 threads)\nMorphological filter: 39% (1 threads)\nMorphological filter: 40% (1 threads)\nMorphological filter: 41% (1 threads)\nMorphological filter: 42% (1 threads)\nMorphological filter: 43% (1 threads)\nMorphological filter: 44% (1 threads)\nMorphological filter: 45% (1 threads)\nMorphological filter: 46% (1 threads)\nMorphological filter: 47% (1 threads)\nMorphological filter: 48% (1 threads)\nMorphological filter: 49% (1 threads)\nMorphological filter: 50% (1 threads)\nMorphological filter: 51% (1 threads)\nMorphological filter: 52% (1 threads)\nMorphological filter: 53% (1 threads)\nMorphological filter: 54% (1 threads)\nMorphological filter: 55% (1 threads)\nMorphological filter: 56% (1 threads)\nMorphological filter: 57% (1 threads)\nMorphological filter: 58% (1 threads)\nMorphological filter: 59% (1 threads)\nMorphological filter: 60% (1 threads)\nMorphological filter: 61% (1 threads)\nMorphological filter: 62% (1 threads)\nMorphological filter: 63% (1 threads)\nMorphological filter: 64% (1 threads)\nMorphological filter: 65% (1 threads)\nMorphological filter: 66% (1 threads)\nMorphological filter: 67% (1 threads)\nMorphological filter: 68% (1 threads)\nMorphological filter: 69% (1 threads)\nMorphological filter: 70% (1 threads)\nMorphological filter: 71% (1 threads)\nMorphological filter: 72% (1 threads)\nMorphological filter: 73% (1 threads)\nMorphological filter: 74% (1 threads)\nMorphological filter: 75% (1 threads)\nMorphological filter: 76% (1 threads)\nMorphological filter: 77% (1 threads)\nMorphological filter: 78% (1 threads)\nMorphological filter: 79% (1 threads)\nMorphological filter: 80% (1 threads)\nMorphological filter: 81% (1 threads)\nMorphological filter: 82% (1 threads)\nMorphological filter: 83% (1 threads)\nMorphological filter: 84% (1 threads)\nMorphological filter: 85% (1 threads)\nMorphological filter: 86% (1 threads)\nMorphological filter: 87% (1 threads)\nMorphological filter: 88% (1 threads)\nMorphological filter: 89% (1 threads)\nMorphological filter: 90% (1 threads)\nMorphological filter: 91% (1 threads)\nMorphological filter: 92% (1 threads)\nMorphological filter: 93% (1 threads)\nMorphological filter: 94% (1 threads)\nMorphological filter: 95% (1 threads)\nMorphological filter: 96% (1 threads)\nMorphological filter: 97% (1 threads)\nMorphological filter: 98% (1 threads)\nMorphological filter: 99% (1 threads)\n\n#las &lt;- classify_ground(las, algorithm = pmf())\n\n# this is 3d so wont render on datalabs\n#plot(las, color = \"Classification\", size = 3, bg = \"white\") \n\n\n# can subset out the ground just to look at that:\n\ngnd &lt;- filter_ground(las)\n# this plots the point cloud of the ground\n\n\nplot(gnd, size = 3, bng= \"white\")\n\n\n### cloth fold simulation method of ground classification: \n\nlibrary(RCSF)\n\nmycsf &lt;- csf(sloop_smooth = FALSE, rigidness = 2)\nlas &lt;- classify_ground(las, mycsf)\n\n#plot_crossection(las, colour_by = factor(Classification))\n\n# plotting cross sections of the ground\n#las_f &lt;- las\n#las_f@data$Classification &lt;- as.factor(las_f@data$Classification)\n#levels(las_f@data$Classification) &lt;- c(\"ground\", \"low veg\", \"med veg\", \"high veg\",\n#                                     \"building\", \"noise\", \"10\",\"13\", \"14\" ,\n#                                     \"15\", \"18\", \"22\" )\n\nv_n &lt;- seq(0.1, 0.95, by = 0.1)\nfor(i in 1:length(v_n)){\n  n &lt;- v_n[i]\n  p1 = c(min(las@data$X), quantile(las@data$Y, n))\n  p2 = c(max(las@data$X), quantile(las@data$Y,n))\n  data_clip &lt;- clip_transect(las, p1, p2, 4)\n  \n  g &lt;- ggplot(data_clip@data, aes(X,Z, colour= factor(Classification))) + \n    geom_point(size = 0.5) + \n    #coord_equal() + \n    theme(axis.title.y=element_blank(),\n          axis.title.x=element_blank()) +\n    theme(legend.position=\"bottom\") +\n    scale_colour_brewer(palette= \"Paired\")\n  \n  assign(paste0(\"g_\", n), g)\n  \n}\n\n\nggarrange(g_0.1, g_0.2, g_0.3, g_0.4, g_0.5,\n          g_0.6, g_0.7, g_0.8, g_0.9,\n          ncol = 1, \n          common.legend = T, \n          legend.position = \"bottom\")\n\n# can also use the cloth simulation to select the ground\n# or multiscale curvature classification",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html#the-digital-terrain-model",
    "href": "lidar_processing.html#the-digital-terrain-model",
    "title": "3  LiDAR data processing",
    "section": "3.2 The digital terrain model:",
    "text": "3.2 The digital terrain model:\nDTM is the image of the ground do this after you have classified the ground\nhave different methods like invert distance weighting, kriging triangular irregular network\n\ndtm_tin &lt;- rasterize_terrain(las, res = 2, algorithm = tin())\nplot(dtm_tin)\nif(FALSE){\nplot_dtm3d(dtm_tin, bg = \"white\") \n}\n\n# duifferent ways of producing digital terrain model\n#dtm &lt;- rasterize_terrain(las, algorithm = tin(), pkg =\"terra\")\nif(FALSE){\nplot_dtm3d(dtm, bg = \"white\") \n}\n\n\n#dtm_prod &lt;- terrain(dtm, v = c(\"slope\", \"aspect\"), unit = \"radians\")\n#dtm_hillshade &lt;- shade(slope = dtm_prod$slope, aspect = dtm_prod$aspect)\nif(FALSE){\nplot(dtm_hillshade, col =gray(0:30/30), legend = FALSE)\n}\nif(FALSE){\ndtm &lt;- raster::raster(dtm_tin)\n\nelmat &lt;- raster_to_matrix(dtm)\nmap &lt;- elmat %&gt;%\n  sphere_shade(texture = \"imhof1\", progbar = FALSE) %&gt;%\n  add_water(detect_water(elmat), color = \"imhof1\") %&gt;%\n  add_shadow(ray_shade(elmat, progbar = FALSE), 0.5) %&gt;%\n  add_shadow(ambient_shade(elmat, progbar = FALSE), 0)\n\nplot_map(map)\n\n### can then normalise the height based on the dtm:\nnlas &lt;- normalize_height(las, knnidw())\n\nplot(nlas, size = 4, bg = \"white\")\n\n# here I've just manually removed Z values &lt; 0 which is not good:\n  # its a sign that the dtm has incorrectly classified the ground\n  # at several points: but there were only like 3 isolated points so \n  # for now I think this is fine.\n  \n  nlas &lt;- nlas[nlas@data$Z &gt;0,]\n  plot(nlas, size = 4, bg = \"white\")\n  \n  hist(filter_ground(nlas)$Z,   breaks = seq(-0.6, 0.6, 0.01), main = \"\", xlab = \"Elevation\")\n  }",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html#classification-term",
    "href": "lidar_processing.html#classification-term",
    "title": "3  LiDAR data processing",
    "section": "3.3 Classification term",
    "text": "3.3 Classification term\nclassification listed as numbers 2,3,4,5,6,10,13,15,18,22 table(las@data$Classification)\nchrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/http://www.asprs.org/wp-content/uploads/2019/07/LAS_1_4_r15.pdf\nASPRS specification of standard point classes: 0 = Created, never classified 1 = unclassified 2 = ground 3 = low vegetation 4 = medium vegetation 5 = high vegetation 6 = building 7 = low point (noise) 8 = model key point (mass point) 9 = water 10, 11 = reserved for ASPRS definition 12 = overlap points 13 - 31 = reserved for ASPRS definition\nCan change classification based on rules:\n\n# Classifies the points that are NOT in the lake and that are NOT ground points as class 5\n\n################\n#plot(las, color = \"Classification\")\n\nnonveg &lt;- filter_poi(las, Classification != LASHIGHVEGETATION)\nveg &lt;- filter_poi(las, Classification == LASHIGHVEGETATION)\n\nplot(las, color = \"Classification\", bg = \"white\", size = 3)\n\n## cross section 2d rendering:\nsummary(las)\n\n## function:\n\nplot_crossection &lt;- function(las,\n                             p1 = c(min(las@data$X), mean(las@data$Y)),\n                             p2 = c(max(las@data$X), mean(las@data$Y)),\n                             width = 4, colour_by = NULL)\n{\n  colour_by &lt;- enquo(colour_by)\n  data_clip &lt;- clip_transect(las, p1, p2, width)\n  p &lt;- ggplot(data_clip@data, aes(X,Z)) + \n    geom_point(size = 0.5) + \n    coord_equal() + \n    theme_minimal()\n  \n  if (!is.null(colour_by))\n    p &lt;- p + aes(color = !!colour_by) + labs(color = \"\") +\n    theme(legend.position=\"bottom\")\n  \n  return(p)\n}\n\nplot_crossection(las)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html#digital-surface-model-and-canopy-height-model",
    "href": "lidar_processing.html#digital-surface-model-and-canopy-height-model",
    "title": "3  LiDAR data processing",
    "section": "3.4 DIGITAL SURFACE MODEL and canopy height model:",
    "text": "3.4 DIGITAL SURFACE MODEL and canopy height model:\nraster layer that report the highest elevation for the ALS returns\n\n# Can specify the thr and the edg\n# Can specify point to raster based or triangulation based\n# Includes the Khosravirpour et al pitfree algorithm\n\nchm &lt;- rasterize_canopy(las, res = 2, algorithm = p2r())\ncol &lt;- height.colors(25)\nplot(chm, col = col)\n\n# can decrease the resolution to cover the empty areas\n# can add a circle of known radius that simulates that the laser is not a point\n# but a circle\n\n# can also fill in the unfilled areas by kriging\n# this is more time consuming\n# but it also looks a LOT BETTER\nchm &lt;- rasterize_canopy(las, res = 0.5, p2r(0.2, na.fill = tin()))\nplot(chm, col = col)\n\n#png(\"outputs/chm_11_01.png\", width = 15, height = 15, units = \"cm\", res = 600)\n#plot(chm, col= col)\n#dev.off()\n\n#plot(chm, color = \"Intensity\", bg = \"white\", legend = TRUE)\n\n# overlays: need a dtm for this to work\n# think this is a pop out\nx &lt;- plot(las, bg = \"white\", size = 3)\nadd_dtm3d(x, chm)\n\n\n# lidR does not include tools to fill empty pixels but terra does:\nif(FALSE){\n  fill.na &lt;- function(x, i=5) { \n    if (is.na(x)[i]) { return(mean(x, na.rm = TRUE)) } else { return(x[i]) }}\n  \n  w &lt;- matrix(1, 3, 3)\n  \n  chm &lt;- rasterize_canopy(las, res = 0.5, \n                          algorithm = p2r(subcircle = 0.25), pkg = \"terra\")\n  filled &lt;- terra::focal(chm, w, fun = fill.na)\n  smoothed &lt;- terra::focal(chm, w, fun = mean, na.rm = TRUE)\n  \n  chms &lt;- c(chm, filled, smoothed)\n  names(chms) &lt;- c(\"Base\", \"Filled\", \"Smoothed\")\n  plot(chms, col = col)\n}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "lidar_processing.html#locating-trees",
    "href": "lidar_processing.html#locating-trees",
    "title": "3  LiDAR data processing",
    "section": "3.5 Locating trees:",
    "text": "3.5 Locating trees:\n\n# lmf(ws, hmin = 2, shape = c(\"circular\", \"square\"), ws_args = \"Z\")\n# ws:    numeric or function. Length or diameter of the moving window \n# used to detect the local maxima in the units of the input data \n# (usually meters). If it is numeric a fixed window size is used. \n# If it is a function, the function determines the size of the window \n# at any given location on the canopy. By default function takes the \n# height of a given pixel or point as its only argument and return the\n# desired size of the search window when centered on that pixel/point. \n# This can be controled with the 'ws_args' parameter.\n\n# hmin: numeric. Minimum height of a tree. Threshold below which a \n# pixel or a point cannot be a local maxima. Default is 2.\n\n# shape: character. Shape of the moving window used to find the local \n# maxima. Can be \"square\" or \"circular\".\n\n# ws_args: list. Named list of argument for the function 'ws' if 'ws'\n# is a function.\n\nttops &lt;- locate_trees(las, lmf(ws = 20)) \nplot(chm, col = height.colors(50))\nplot(sf::st_geometry(ttops), add = TRUE, pch = 3)\n\n#png(\"outputs/ttops_11_01_ws20.png\", width = 15, height = 15, units = \"cm\", res #= 600)\n\n#plot(chm, col = height.colors(50))\n#plot(sf::st_geometry(ttops), add = TRUE, pch = 3)\n\n#dev.off()\n\n# plot the point cloud\n# It's somehow added on a tree that's 60m tall in the middle of the plot\n# that has no data to support it\n\noffsets &lt;- plot(las, bg = \"white\", size = 3)\nadd_treetops3d(offsets, ttops)\n# num,ber of trees detected is related to the ws value:\n\nttops_3m &lt;- locate_trees(las, lmf(ws = 3))\nttops_11m &lt;- locate_trees(las, lmf(ws = 11))\n\npar(mfrow=c(1,2))\nplot(chm, col = height.colors(50))\nplot(sf::st_geometry(ttops_3m), add = TRUE, pch = 3)\nplot(chm, col = height.colors(50))\nplot(sf::st_geometry(ttops_11m), add = TRUE, pch = 3)\n\n# extract the coordinates of the trees and apply the shift to display the lines\n# in the rendering coordinate system\n\nx &lt;- sf::st_coordinates(ttops)[,1] - offsets[1] \ny &lt;- sf::st_coordinates(ttops)[,2] - offsets[2] \nz &lt;- ttops$Z\n\n\n# Build a GL_LINES matrix for fast rendering\nx &lt;- rep(x, each = 2)\ny &lt;- rep(y, each = 2)\ntmp &lt;- numeric(2*length(z)) \ntmp[2*1:length(z)] &lt;- z\nz &lt;- tmp\nM &lt;- cbind(x,y,z)\n\n# Display lines\nrgl::segments3d(M, col = \"black\", lwd = 2)\n\n\n# individual segmentation:\n\nalgo &lt;- dalponte2016(chm, ttops)\nt &lt;- segment_trees(las, algo) # segment point cloud\nplot(t, bg = \"white\", size = 4, color = \"treeID\") # visualize trees\n# dont feel that confident about this1\n\n# extrtact crowns:\n\ncrowns &lt;- crown_metrics(t, func = .stdtreemetrics, geom = \"convex\")\nplot(crowns[\"convhull_area\"], main = \"Crown area (convex hull)\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>LiDAR data processing</span>"
    ]
  },
  {
    "objectID": "sentinel1.html",
    "href": "sentinel1.html",
    "title": "4  Sentinel 1 SAR time-lapse image",
    "section": "",
    "text": "This example python script to create is adapted from the geemap tutorial: https://geemap.org/notebooks/123_sentinel1_timelapse/\n#python\n\n# !pip install -U geemap\nimport ee\nimport geemap\nMap = geemap.Map()\nMap\nPan and zoom to an area of interest and draw a rectangle on the map.\nroi = Map.user_roi\nif roi is None:\n  roi = ee.Geometry.BBox(117.1132, 3.5227, 117.2214, 3.5843) # change as needed\nMap.addLayer(roi)\nMap.centerObject(roi)\ntimelapse = geemap.sentinel1_timelapse(\n  roi,\n  out_gif=\"sentinel1.gif\",\n  start_year=2019,\n  end_year=2019,\n  start_date=\"04-01\",\n  end_date=\"08-01\",\n  frequency=\"day\",\n  vis_params={\"min\": -30, \"max\": 0},\n  palette=\"Greys\",\n  frames_per_second=3,\n  title=\"Sentinel-1 Timelapse\",\n  add_colorbar=True,\n  colorbar_bg_color=\"gray\",\n)\ngeemap.show_image(timelapse)\nThe following is a time-lapsed SAR image for the Knepp Estate.\n\n\n\nKnepp Esatate Sentinel 1 SAR time lapse",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sentinel 1 SAR time-lapse image</span>"
    ]
  },
  {
    "objectID": "sh_RS_comparison.html#section-1",
    "href": "sh_RS_comparison.html#section-1",
    "title": "5  Strawberry Hill analysis",
    "section": "5.1 ",
    "text": "5.1",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Strawberry Hill analysis</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "6  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary</span>"
    ]
  }
]